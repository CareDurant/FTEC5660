{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "iOEmNJmYQ63C"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 2"
      ],
      "metadata": {
        "id": "tFaf7VErZ1Bf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up"
      ],
      "metadata": {
        "id": "I3g3k3W-qfAv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing packages"
      ],
      "metadata": {
        "id": "6vsESFZylO6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests PyPDF2 gdown\n",
        "!pip install 'markitdown[pdf]'\n",
        "!pip install langchain_mcp_adapters langchain_google_genai langchain-openai"
      ],
      "metadata": {
        "id": "Hrdfpmv9nMpw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98fb59d3-88ec-4534-d84b-b02a607cc321",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2026.1.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.24.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Collecting markitdown[pdf]\n",
            "  Downloading markitdown-0.1.5-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (4.13.5)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (3.4.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (0.7.1)\n",
            "Collecting magika~=0.6.1 (from markitdown[pdf])\n",
            "  Downloading magika-0.6.3-py3-none-manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
            "Collecting markdownify (from markitdown[pdf])\n",
            "  Downloading markdownify-1.2.2-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (2.32.4)\n",
            "Collecting pdfminer-six>=20251230 (from markitdown[pdf])\n",
            "  Downloading pdfminer_six-20260107-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting pdfplumber>=0.11.9 (from markitdown[pdf])\n",
            "  Downloading pdfplumber-0.11.9-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown[pdf]) (8.3.1)\n",
            "Collecting onnxruntime>=1.17.0 (from magika~=0.6.1->markitdown[pdf])\n",
            "  Downloading onnxruntime-1.24.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown[pdf]) (2.0.2)\n",
            "Requirement already satisfied: python-dotenv>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown[pdf]) (1.2.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer-six>=20251230->markitdown[pdf]) (43.0.3)\n",
            "Collecting pdfminer-six>=20251230 (from markitdown[pdf])\n",
            "  Downloading pdfminer_six-20251230-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber>=0.11.9->markitdown[pdf]) (11.3.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber>=0.11.9->markitdown[pdf])\n",
            "  Downloading pypdfium2-5.5.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (68 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m68.1/68.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->markitdown[pdf]) (2.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->markitdown[pdf]) (4.15.0)\n",
            "Requirement already satisfied: six<2,>=1.15 in /usr/local/lib/python3.12/dist-packages (from markdownify->markitdown[pdf]) (1.17.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown[pdf]) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown[pdf]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown[pdf]) (2026.1.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer-six>=20251230->markitdown[pdf]) (2.0.0)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (25.12.19)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (26.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (5.29.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (1.14.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer-six>=20251230->markitdown[pdf]) (3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (1.3.0)\n",
            "Downloading magika-0.6.3-py3-none-manylinux_2_28_x86_64.whl (15.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfplumber-0.11.9-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20251230-py3-none-any.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m113.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdownify-1.2.2-py3-none-any.whl (15 kB)\n",
            "Downloading markitdown-0.1.5-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.4/63.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.24.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-5.5.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, onnxruntime, markdownify, pdfminer-six, magika, pdfplumber, markitdown\n",
            "Successfully installed magika-0.6.3 markdownify-1.2.2 markitdown-0.1.5 onnxruntime-1.24.2 pdfminer-six-20251230 pdfplumber-0.11.9 pypdfium2-5.5.0\n",
            "Collecting langchain_mcp_adapters\n",
            "  Downloading langchain_mcp_adapters-0.2.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting langchain_google_genai\n",
            "  Downloading langchain_google_genai-4.2.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.1.10-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_mcp_adapters) (1.2.13)\n",
            "Requirement already satisfied: mcp>=1.9.2 in /usr/local/lib/python3.12/dist-packages (from langchain_mcp_adapters) (1.26.0)\n",
            "Requirement already satisfied: typing-extensions>=4.14.0 in /usr/local/lib/python3.12/dist-packages (from langchain_mcp_adapters) (4.15.0)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain_google_genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.56.0 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (1.63.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (2.12.3)\n",
            "Requirement already satisfied: openai<3.0.0,>=2.20.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.21.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (4.12.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in /usr/local/lib/python3.12/dist-packages (from google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2.47.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.28.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (9.1.4)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (15.0.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.3.1)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (0.7.3)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (26.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (6.0.3)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (0.14.0)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.4.3)\n",
            "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (4.26.0)\n",
            "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (2.13.0)\n",
            "Requirement already satisfied: pyjwt>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (2.11.0)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.0.22)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (3.2.0)\n",
            "Requirement already satisfied: starlette>=0.27 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.52.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.31.1 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.41.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (0.13.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (4.67.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain_google_genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain_google_genai) (2.41.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (3.11)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (3.0.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (0.30.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (1.0.0)\n",
            "Requirement already satisfied: xxhash>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (3.6.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings>=2.5.2->mcp>=1.9.2->langchain_mcp_adapters) (1.2.1)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (43.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2.5.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.31.1->mcp>=1.9.2->langchain_mcp_adapters) (8.3.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (2.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.6.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (3.0)\n",
            "Downloading langchain_mcp_adapters-0.2.1-py3-none-any.whl (22 kB)\n",
            "Downloading langchain_google_genai-4.2.1-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-1.1.10-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: filetype, langchain-openai, langchain_mcp_adapters, langchain_google_genai\n",
            "Successfully installed filetype-1.2.0 langchain-openai-1.1.10 langchain_google_genai-4.2.1 langchain_mcp_adapters-0.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `VERTEX_API_KEY`.\n",
        "\n",
        "\n",
        "1.   Look for the key icon on the left panel of your colab.\n",
        "2.   Under `Name`, create `VERTEX_API_KEY`.\n",
        "3. Copy your key to `Value`.\n",
        "\n",
        "If you cannot use VERTEX_API_KEY, you can use deepseek models via `DEEPSEEK_API_KEY`. It does not affect your score.\n",
        "\n"
      ],
      "metadata": {
        "id": "BUav-7KdaY_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "#GEMINI_VERTEX_API_KEY = userdata.get('VERTEX_API_KEY')\n",
        "DEEPSEEK_API_KEY = userdata.get('DEEPSEEK_API_KEY')"
      ],
      "metadata": {
        "id": "ueILmCPHci9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download sample CVs"
      ],
      "metadata": {
        "id": "RRbStil_qkQc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading sample_cv.pdf\n",
        "The codes below download the sample CV\n"
      ],
      "metadata": {
        "id": "kCENjOq6owDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gdown\n",
        "\n",
        "folder_id = \"1adYKq7gSSczFP3iikfA8Er-HSZP6VM7D\"\n",
        "folder_url = f\"https://drive.google.com/drive/folders/{folder_id}\"\n",
        "\n",
        "output_dir = \"downloaded_cvs\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "gdown.download_folder(\n",
        "    url=folder_url,\n",
        "    output=output_dir,\n",
        "    quiet=False,\n",
        "    use_cookies=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kCCp8DwPF4L",
        "outputId": "71a9f8a2-ff06-4d0e-d18a-8d7397507d94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1NR1RUKx4GyM7QOBxKXkfh4e8jUkxFCsp CV_1.pdf\n",
            "Processing file 16lrd-uO8AAnCnv7UG9Rs_Nk6SUu0Iwbs CV_2.pdf\n",
            "Processing file 15hVEuBan_EKhEty2aZBd6rcpDpP4o7Vr CV_3.pdf\n",
            "Processing file 1Y2w_mAUEhg4vZBdvvR-0n3Jf2mKuGDRk CV_4.pdf\n",
            "Processing file 1PLwkva-pdua6ZVvmLg9mxHeljq9D8C_C CV_5.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1NR1RUKx4GyM7QOBxKXkfh4e8jUkxFCsp\n",
            "To: /content/downloaded_cvs/CV_1.pdf\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 147k/147k [00:00<00:00, 27.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16lrd-uO8AAnCnv7UG9Rs_Nk6SUu0Iwbs\n",
            "To: /content/downloaded_cvs/CV_2.pdf\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75.1k/75.1k [00:00<00:00, 54.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15hVEuBan_EKhEty2aZBd6rcpDpP4o7Vr\n",
            "To: /content/downloaded_cvs/CV_3.pdf\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72.0k/72.0k [00:00<00:00, 68.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Y2w_mAUEhg4vZBdvvR-0n3Jf2mKuGDRk\n",
            "To: /content/downloaded_cvs/CV_4.pdf\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73.3k/73.3k [00:00<00:00, 11.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PLwkva-pdua6ZVvmLg9mxHeljq9D8C_C\n",
            "To: /content/downloaded_cvs/CV_5.pdf\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97.9k/97.9k [00:00<00:00, 12.3MB/s]\n",
            "Download completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['downloaded_cvs/CV_1.pdf',\n",
              " 'downloaded_cvs/CV_2.pdf',\n",
              " 'downloaded_cvs/CV_3.pdf',\n",
              " 'downloaded_cvs/CV_4.pdf',\n",
              " 'downloaded_cvs/CV_5.pdf']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "#  Load and display all CV PDFs in order\n",
        "# =====================================================\n",
        "import os\n",
        "from markitdown import MarkItDown\n",
        "\n",
        "cv_dir = \"downloaded_cvs\"\n",
        "\n",
        "# Initialize MarkItDown\n",
        "md = MarkItDown(enable_plugins=False)\n",
        "\n",
        "# Collect and sort PDFs numerically\n",
        "pdf_files = sorted(\n",
        "    [f for f in os.listdir(cv_dir) if f.lower().endswith(\".pdf\")],\n",
        "    key=lambda x: int(\"\".join(filter(str.isdigit, x)))  # CV_1.pdf â†’ 1\n",
        ")\n",
        "\n",
        "all_cvs = []\n",
        "\n",
        "for pdf_name in pdf_files:\n",
        "    pdf_path = os.path.join(cv_dir, pdf_name)\n",
        "    result = md.convert(pdf_path)\n",
        "\n",
        "    all_cvs.append({\n",
        "        \"file\": pdf_name,\n",
        "        \"text\": result.text_content\n",
        "    })\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"ğŸ“„ {pdf_name}\")\n",
        "    print(\"=\" * 80)\n",
        "    print(result.text_content)\n",
        "    print(\"\\n\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2akmVn9LODIu",
        "outputId": "23702891-8f97-4a60-eb8b-b61c1595c679",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "ğŸ“„ CV_1.pdf\n",
            "================================================================================\n",
            "|     |     |     |     | John         |           | Smith        |                   |     |     |\n",
            "| --- | --- | --- | --- | ------------ | --------- | ------------ | ----------------- | --- | --- |\n",
            "|     |     |     |     | Marketing    |           | Professional |                   |     |     |\n",
            "|     |     |     |     | + Singapore, | Singapore |              | (cid:209) Kowloon |     |     |\n",
            "Experience\n",
            "|                |                  |     |          |                     |              |            |     | 2020 â€“ | Present |\n",
            "| -------------- | ---------------- | --- | -------- | ------------------- | ------------ | ---------- | --- | ------ | ------- |\n",
            "| Engineer,      | ByteDance        |     |          |                     |              |            |     |        |         |\n",
            "| â€¢ Worked       | in a fast-paced, |     | global   | technology          | environment. |            |     |        |         |\n",
            "| â€¢ Collaborated | across           |     | teams to | support large-scale |              | platforms. |     |        |         |\n",
            "â€¢ Applied analytical and problem-solving skills in production systems.\n",
            "Education\n",
            "| McGill   | University |       |              |     |     |     |     | Graduated | 2009 |\n",
            "| -------- | ---------- | ----- | ------------ | --- | --- | --- | --- | --------- | ---- |\n",
            "| Bachelor | of Science | (BSc) | in Marketing |     |     |     |     |           |      |\n",
            "Skills\n",
            "| Content | Creation | SEO | Social | Media |     |     |     |     |     |\n",
            "| ------- | -------- | --- | ------ | ----- | --- | --- | --- | --- | --- |\n",
            "1\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ğŸ“„ CV_2.pdf\n",
            "================================================================================\n",
            "| Minh | Pham |     |     |     |     |     |\n",
            "| ---- | ---- | --- | --- | --- | --- | --- |\n",
            "Design Professional\n",
            "| Beijing,     | China | Hong     | Kong     |               |        |              |                |\n",
            "| ------------ | ---------------- | -------- | ------------- | ------ | ------------ | -------------- |\n",
            "| Professional | Experience       |          |               |        |              |                |\n",
            "| Manager,     | BCG              |          |               |        |              | 2022 â€“ Present |\n",
            "| â€¢ Led        | cross-functional | teams on | client-facing | design | initiatives. |                |\n",
            "â€¢ Managed project timelines, deliverables, and stakeholder communication.\n",
            "| â€¢ Applied | design thinking | to business | and | strategy | problems. |             |\n",
            "| --------- | --------------- | ----------- | --- | -------- | --------- | ----------- |\n",
            "| Analyst,  | Tencent         |             |     |          |           | 2013 â€“ 2017 |\n",
            "â€¢ Conducted market and product analysis to support decision-making.\n",
            "| â€¢ Collaborated | with    | design and   | engineering | teams.      |     |     |\n",
            "| -------------- | ------- | ------------ | ----------- | ----------- | --- | --- |\n",
            "| â€¢ Produced     | reports | and insights | for senior  | leadership. |     |     |\n",
            "Education\n",
            "| BSc in         | Design  |      |     |     |     | 2011 |\n",
            "| -------------- | ------- | ---- | --- | --- | --- | ---- |\n",
            "| The University | of Hong | Kong |     |     |     |      |\n",
            "Skills\n",
            "| â€¢ UI/UX | Design |     |     |     |     |     |\n",
            "| ------- | ------ | --- | --- | --- | --- | --- |\n",
            "â€¢ Prototyping\n",
            "| â€¢ Graphic | Design |     |     |     |     |     |\n",
            "| --------- | ------ | --- | --- | --- | --- | --- |\n",
            "1\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ğŸ“„ CV_3.pdf\n",
            "================================================================================\n",
            "| Wei Zhang    |              |           |     |     |     | Munich, Germany   |\n",
            "| ------------ | ------------ | --------- | --- | --- | --- | ----------------- |\n",
            "| Consulting   | Professional |           |     |     |     | Sydney (Hometown) |\n",
            "| Professional | Experience   |           |     |     |     |                   |\n",
            "| 2013         | â€“ Present    | Engineer, | PwC |     |     |                   |\n",
            "â€¢ Supportedconsultingengagementsacrossmultipleclient\n",
            "projects.\n",
            "|     |     | â€¢ Performed | data analysis | to inform | strategic recommen- |     |\n",
            "| --- | --- | ----------- | ------------- | --------- | ------------------- | --- |\n",
            "dations.\n",
            "|     |     | â€¢ Collaborated  | with         | cross-functional | teams in | a profes- |\n",
            "| --- | --- | --------------- | ------------ | ---------------- | -------- | --------- |\n",
            "|     |     | sional services | environment. |                  |          |           |\n",
            "Education\n",
            "| 2015 |     | BSc in Consulting |          |     |     |     |\n",
            "| ---- | --- | ----------------- | -------- | --- | --- | --- |\n",
            "|      |     | University        | of Tokyo |     |     |     |\n",
            "Skills\n",
            "| Analytical |     |     | Data Analysis,       | Problem | Solving |     |\n",
            "| ---------- | --- | --- | -------------------- | ------- | ------- | --- |\n",
            "| Business   |     |     | Strategy, PowerPoint |         |         |     |\n",
            "1\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ğŸ“„ CV_4.pdf\n",
            "================================================================================\n",
            "| Rahul | Sharma |     |     |     |     |     |     |     |     |\n",
            "| ----- | ------ | --- | --- | --- | --- | --- | --- | --- | --- |\n",
            "Legal Professional\n",
            "| Singapore    | (Hometown) | | Singapore              |           | / Philippines |             |        |             |     |         |\n",
            "| ------------ | ---------- | ------------------------ | --------- | ------------- | ----------- | ------ | ----------- | --- | ------- |\n",
            "| Professional |            | Experience               |           |               |             |        |             |     |         |\n",
            "| 2021         | â€“ 2027     | Senior                   | Engineer, | Microsoft     |             |        |             |     |         |\n",
            "|              |            | â€¢ Led compliance-focused |           |               | initiatives | within | large-scale |     | techni- |\n",
            "cal teams.\n",
            "â€¢ Advisedonregulatory,legal,andriskconsiderationsforcom-\n",
            "plex systems.\n",
            "|     |     | â€¢ Worked | at the | intersection |     | of law, | technology, | and | gover- |\n",
            "| --- | --- | -------- | ------ | ------------ | --- | ------- | ----------- | --- | ------ |\n",
            "nance.\n",
            "| 2020 | â€“ 2023 | Consultant, | StartupXYZ |               |     |            |                 |     |      |\n",
            "| ---- | ------ | ----------- | ---------- | ------------- | --- | ---------- | --------------- | --- | ---- |\n",
            "|      |        | â€¢ Provided  | legal      | and strategic |     | consulting | for early-stage |     | com- |\n",
            "panies.\n",
            "|     |     | â€¢ Supported | contract | review, |     | compliance, | and operational |     | risk |\n",
            "| --- | --- | ----------- | -------- | ------- | --- | ----------- | --------------- | --- | ---- |\n",
            "management.\n",
            "|     |     | â€¢ Engaged | with | cross-functional |     | and | international | stakehold- |     |\n",
            "| --- | --- | --------- | ---- | ---------------- | --- | --- | ------------- | ---------- | --- |\n",
            "ers.\n",
            "Education\n",
            "2021\n",
            "|     |     | PhD in   | Legal      | Studies |     |     |     |     |     |\n",
            "| --- | --- | -------- | ---------- | ------- | --- | --- | --- | --- | --- |\n",
            "|     |     | Tsinghua | University |         |     |     |     |     |     |\n",
            "Skills\n",
            "|     |     | Compliance,   | Litigation, |           | Contract | Review    |     |     |     |\n",
            "| --- | --- | ------------- | ----------- | --------- | -------- | --------- | --- | --- | --- |\n",
            "|     |     | Web3, Machine |             | Learning, | Quantum  | Computing |     |     |     |\n",
            "1\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ğŸ“„ CV_5.pdf\n",
            "================================================================================\n",
            "| Rahul | Sharma |     |     |     |     |     |     |\n",
            "| ----- | ------ | --- | --- | --- | --- | --- | --- |\n",
            "AI Professional\n",
            "| London     | | Hong Kong | | Singapore | (Hometown) |              |               |                |               |\n",
            "| ---------- | ----------- | ----------- | ---------- | ------------ | ------------- | -------------- | ------------- |\n",
            "| Core       | Skills      |             |            | Professional | Experience    |                |               |\n",
            "| Machine    | Learning    | & AI        |            | Senior       | Engineer      |                |               |\n",
            "|            |             |             |            | EY           |               |                | Current       |\n",
            "| â€¢ Advanced | AI Systems  |             |            |              |               |                |               |\n",
            "|            |             |             |            | â€¢ Designed   | and evaluated | AI-driven      | solutions for |\n",
            "|            |             |             |            | enterprise   | clients.      |                |               |\n",
            "| â€¢ Machine  | Learning    | (ML)        |            |              |               |                |               |\n",
            "|            |             |             |            | â€¢ Applied    | ML techniques | to large-scale | business      |\n",
            "| â€¢ Natural  | Language    | Processing  | (NLP)      | problems.    |               |                |               |\n",
            "Consultant\n",
            "| Frameworks   | &   | Tools |     |             |             |          |             |\n",
            "| ------------ | --- | ----- | --- | ----------- | ----------- | -------- | ----------- |\n",
            "|              |     |       |     | StartupXYZ  |             |          | 2019 â€“ 2021 |\n",
            "| â€¢ TensorFlow |     |       |     | â€¢ Provided  | AI and data | strategy | advisory to |\n",
            "|              |     |       |     | early-stage | companies.  |          |             |\n",
            "â€¢ PyTorch\n",
            "Senior Analyst\n",
            "|     |     |     |     | DataForge |     | 2016 | â€“ Present |\n",
            "| --- | --- | --- | --- | --------- | --- | ---- | --------- |\n",
            "â€¢ Python\n",
            "|     |     |     |     | â€¢ Conducted | advanced | data analysis | and model |\n",
            "| --- | --- | --- | --- | ----------- | -------- | ------------- | --------- |\n",
            "evaluation.\n",
            "Lead Scientist\n",
            "Education\n",
            "|     |     |     |     | UrbanFlow |     |     | 2010 â€“ 2017 |\n",
            "| --- | --- | --- | --- | --------- | --- | --- | ----------- |\n",
            "PhD in Artificial Intelligence â€¢ Led research initiatives in applied AI systems.\n",
            "| University | of Tokyo |     |     |            |                    |                |     |\n",
            "| ---------- | -------- | --- | --- | ---------- | ------------------ | -------------- | --- |\n",
            "| 2012       |          |     |     | â€¢ Mentored | junior researchers | and engineers. |     |\n",
            "1\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to our MCP server\n",
        "\n",
        "Documentation about MCP: https://modelcontextprotocol.io/docs/getting-started/intro.\n",
        "\n",
        "Using MCP servers in Langchain https://docs.langchain.com/oss/python/langchain/mcp."
      ],
      "metadata": {
        "id": "VA2GvPWTQFt9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check which tools that the MCP server provide"
      ],
      "metadata": {
        "id": "5mbkH9xHXfmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import json\n",
        "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
        "\n",
        "client = MultiServerMCPClient({\n",
        "    \"social_graph\": {\n",
        "        \"transport\": \"http\",\n",
        "        \"url\": \"https://ftec5660.ngrok.app/mcp\",\n",
        "        \"headers\": {\"ngrok-skip-browser-warning\": \"true\"}\n",
        "    }\n",
        "})\n",
        "\n",
        "mcp_tools = await client.get_tools()\n",
        "for tool in mcp_tools:\n",
        "    print(tool.name)\n",
        "    print(tool.description)\n",
        "    print(tool.args)\n",
        "    print(\"\\n\\n------------------------------------------------------\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6h0311KbN9A3",
        "outputId": "0a507569-8082-464e-8c33-32b5cdb022e5",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "search_facebook_users\n",
            "Search for Facebook users by display name (supports partial and fuzzy matching).\n",
            "\n",
            "Args:\n",
            "    q: Search query string (case-insensitive, matches any part of display name)\n",
            "       Examples: \"John\", \"john smith\", \"Smith\"\n",
            "    limit: Maximum number of results to return (default: 20, max: 20)\n",
            "    fuzzy: Enable fuzzy matching if exact search returns no results (default: True)\n",
            "\n",
            "Returns:\n",
            "    List of user dictionaries, each containing:\n",
            "    - id (int): Unique Facebook user ID for use with get_facebook_profile()\n",
            "    - display_name (str): User's Facebook display name (may differ from legal name)\n",
            "    - city (str): Current city of residence\n",
            "    - country (str): Country of residence\n",
            "    - match_type (str): \"exact\" or \"fuzzy\" (indicates search method used)\n",
            "    \n",
            "    Returns empty list [] if no matches found.\n",
            "\n",
            "Example:\n",
            "    search_facebook_users(\"Alex Chan\", limit=5)\n",
            "    â†’ [{\"id\": 123, \"display_name\": \"Alex Chan\", \"city\": \"Hong Kong\", \"country\": \"Hong Kong\", \"match_type\": \"exact\"}]\n",
            "    \n",
            "    search_facebook_users(\"Alx Chn\", limit=5)  # Typo - uses fuzzy matching\n",
            "    â†’ [{\"id\": 123, \"display_name\": \"Alex Chan\", \"city\": \"Hong Kong\", \"country\": \"Hong Kong\", \"match_type\": \"fuzzy\"}]\n",
            "\n",
            "Use case:\n",
            "    First step in CV verification - find candidate's Facebook profile to cross-check\n",
            "    personal information, location, and social connections. Handles typos and variations.\n",
            "{'q': {'type': 'string'}, 'limit': {'default': 20, 'type': 'integer'}, 'fuzzy': {'default': True, 'type': 'boolean'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "get_facebook_profile\n",
            "Retrieve complete Facebook profile including personal info, bio, relationships, and activity.\n",
            "\n",
            "Args:\n",
            "    user_id: Facebook user ID obtained from search_facebook_users()\n",
            "\n",
            "Returns:\n",
            "    Dictionary containing:\n",
            "    - id (int): Facebook user ID\n",
            "    - display_name (str): Public display name (may be nickname)\n",
            "    - original_name (str): Original/legal name from LinkedIn\n",
            "    - city (str): Current city\n",
            "    - country (str): Current country\n",
            "    - hometown (str|None): City/region where user grew up\n",
            "    - bio (str): Personal biography/interests\n",
            "    - status (str|None): Relationship status (Single, Married, etc.)\n",
            "    - education (str|None): Highest education level\n",
            "    - current_job (str|None): Current job title\n",
            "    - current_company (str|None): Current employer\n",
            "    - interests (str): Comma-separated hobbies/interests\n",
            "    - friends (List[int]): List of friend user IDs\n",
            "    - posts (List[dict]): Recent posts with id and content\n",
            "    \n",
            "    Returns {\"error\": \"User not found\"} if user_id is invalid.\n",
            "\n",
            "Example:\n",
            "    get_facebook_profile(123)\n",
            "    â†’ {\n",
            "        \"id\": 123,\n",
            "        \"display_name\": \"Sam Chan\",\n",
            "        \"original_name\": \"Alex Chan\",\n",
            "        \"city\": \"Hong Kong\",\n",
            "        \"hometown\": \"Kowloon\",\n",
            "        \"bio\": \"Software professional | Photography enthusiast\",\n",
            "        \"status\": \"Married\",\n",
            "        \"current_job\": \"Senior Engineer\",\n",
            "        \"current_company\": \"Google\",\n",
            "        \"friends\": [124, 125, 126],\n",
            "        \"posts\": [{\"id\": 1, \"content\": \"Excited to announce...\"}]\n",
            "    }\n",
            "\n",
            "Use case:\n",
            "    Verify candidate's personal details, check for name discrepancies,\n",
            "    validate current employment, and assess social connections.\n",
            "{'user_id': {'type': 'integer'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "get_facebook_mutual_friends\n",
            "Find mutual friends between two Facebook users (useful for verifying social connections).\n",
            "\n",
            "Args:\n",
            "    user_id_1: First Facebook user ID\n",
            "    user_id_2: Second Facebook user ID\n",
            "\n",
            "Returns:\n",
            "    Dictionary containing:\n",
            "    - user_1_id (int): First user's ID\n",
            "    - user_2_id (int): Second user's ID\n",
            "    - mutual_friends (List[int]): List of shared friend IDs\n",
            "    - mutual_count (int): Number of mutual friends\n",
            "    \n",
            "    Returns {\"error\": \"...\"} if either user not found.\n",
            "\n",
            "Example:\n",
            "    get_facebook_mutual_friends(123, 456)\n",
            "    â†’ {\"user_1_id\": 123, \"user_2_id\": 456, \"mutual_friends\": [789, 790], \"mutual_count\": 2}\n",
            "\n",
            "Use case:\n",
            "    Verify professional or personal relationships claimed in CV/references.\n",
            "{'user_id_1': {'type': 'integer'}, 'user_id_2': {'type': 'integer'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "search_linkedin_people\n",
            "Search LinkedIn profiles by name, headline, skills, or keywords with optional filters.\n",
            "\n",
            "Args:\n",
            "    q: Search query (matches name, headline, summary, or skill names)\n",
            "       Examples: \"software engineer\", \"Python\", \"data scientist\", \"Alex Chan\"\n",
            "    location: Filter by location (optional, case-insensitive, matches city OR country)\n",
            "              Examples: \"Hong Kong\", \"Singapore\", \"China\", \"USA\", \"New York\"\n",
            "    industry: Filter by industry (optional, case-insensitive)\n",
            "              Examples: \"Software\", \"Finance\", \"AI\", \"Consulting\"\n",
            "    limit: Maximum results to return (default: 20, max: 20)\n",
            "    fuzzy: Enable fuzzy matching if exact search returns no results (default: True)\n",
            "\n",
            "Returns:\n",
            "    List of profile dictionaries, each containing:\n",
            "    - id (int): LinkedIn profile ID for use with get_linkedin_profile()\n",
            "    - name (str): Full name\n",
            "    - headline (str): Professional headline/title\n",
            "    - industry (str): Industry sector\n",
            "    - location (str): \"City, Country\" format\n",
            "    - years_experience (int): Total years of work experience\n",
            "    - match_type (str): \"exact\" or \"fuzzy\"\n",
            "    \n",
            "    Returns empty list [] if no matches found.\n",
            "\n",
            "Example:\n",
            "    search_linkedin_people(\"Python developer\", location=\"Hong Kong\", limit=5)\n",
            "    â†’ [{\"id\": 456, \"name\": \"Alex Chan\", \"headline\": \"Senior Python Developer\", \n",
            "        \"industry\": \"Software\", \"location\": \"Hong Kong, Hong Kong\", \"years_experience\": 8, \"match_type\": \"exact\"}]\n",
            "    \n",
            "    search_linkedin_people(\"Pythn develper\", location=\"Hong Kong\", limit=5)  # Typo\n",
            "    â†’ [{\"id\": 456, \"name\": \"Alex Chan\", \"headline\": \"Senior Python Developer\", \n",
            "        \"industry\": \"Software\", \"location\": \"Hong Kong, Hong Kong\", \"years_experience\": 8, \"match_type\": \"fuzzy\"}]\n",
            "\n",
            "Use case:\n",
            "    Find candidate's LinkedIn profile using name, skills, or job title from CV.\n",
            "    Use location filter to narrow down results when common names exist. Handles typos.\n",
            "{'q': {'type': 'string'}, 'location': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None}, 'industry': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None}, 'limit': {'default': 20, 'type': 'integer'}, 'fuzzy': {'default': True, 'type': 'boolean'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "get_linkedin_profile\n",
            "Retrieve complete LinkedIn professional profile including work history, education, and skills.\n",
            "\n",
            "Args:\n",
            "    person_id: LinkedIn profile ID obtained from search_linkedin_people()\n",
            "\n",
            "Returns:\n",
            "    Dictionary containing:\n",
            "    - id (int): LinkedIn profile ID\n",
            "    - name (str): Full name\n",
            "    - headline (str): Professional headline\n",
            "    - city (str): Current city\n",
            "    - country (str): Current country\n",
            "    - industry (str): Primary industry\n",
            "    - status (str): Employment status (employed, open_to_work, hiring, student)\n",
            "    - years_experience (int): Total years of professional experience\n",
            "    - summary (str): Professional summary/bio\n",
            "    \n",
            "    - skills (List[dict]): Each containing:\n",
            "        * name (str): Skill name (e.g., \"Python\", \"Machine Learning\")\n",
            "        * proficiency (int): Skill level 1-5 (1=beginner, 5=expert)\n",
            "    \n",
            "    - experience (List[dict]): Work history, each containing:\n",
            "        * company (str): Employer name\n",
            "        * title (str): Job title\n",
            "        * seniority (str): Level (junior, mid, senior)\n",
            "        * start_year (int): Employment start year\n",
            "        * end_year (int|None): Employment end year (None if current)\n",
            "        * is_current (bool): Whether currently employed here\n",
            "    \n",
            "    - education (List[dict]): Academic history, each containing:\n",
            "        * school (str): Institution name\n",
            "        * degree (str): Degree type (BSc, MSc, MBA, PhD)\n",
            "        * field (str): Field of study\n",
            "        * start_year (int): Start year\n",
            "        * end_year (int): Graduation year\n",
            "    \n",
            "    Returns {\"error\": \"Profile not found\"} if person_id is invalid.\n",
            "\n",
            "Example:\n",
            "    get_linkedin_profile(456)\n",
            "    â†’ {\n",
            "        \"id\": 456,\n",
            "        \"name\": \"Alex Chan\",\n",
            "        \"headline\": \"Senior Software Engineer\",\n",
            "        \"years_experience\": 8,\n",
            "        \"skills\": [\n",
            "            {\"name\": \"Python\", \"proficiency\": 5},\n",
            "            {\"name\": \"Docker\", \"proficiency\": 4}\n",
            "        ],\n",
            "        \"experience\": [\n",
            "            {\n",
            "                \"company\": \"Google\",\n",
            "                \"title\": \"Senior Engineer\",\n",
            "                \"seniority\": \"senior\",\n",
            "                \"start_year\": 2020,\n",
            "                \"end_year\": None,\n",
            "                \"is_current\": True\n",
            "            }\n",
            "        ],\n",
            "        \"education\": [\n",
            "            {\n",
            "                \"school\": \"HKUST\",\n",
            "                \"degree\": \"BSc\",\n",
            "                \"field\": \"Computer Science\",\n",
            "                \"start_year\": 2010,\n",
            "                \"end_year\": 2014\n",
            "            }\n",
            "        ]\n",
            "    }\n",
            "\n",
            "Use case:\n",
            "    Primary tool for CV verification - compare claimed experience, education,\n",
            "    skills, and employment dates against LinkedIn ground truth.\n",
            "{'person_id': {'type': 'integer'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "get_linkedin_interactions\n",
            "Retrieve LinkedIn engagement data showing who has interacted with a person's content.\n",
            "\n",
            "Args:\n",
            "    person_id: LinkedIn profile ID\n",
            "\n",
            "Returns:\n",
            "    Dictionary containing:\n",
            "    - profile_id (int): The person's LinkedIn ID\n",
            "    - post_count (int): Number of posts made\n",
            "    - total_likes (int): Total likes received across all posts\n",
            "    - liked_by (List[int]): Unique profile IDs who have liked this person's posts\n",
            "    - engagement_score (float): Likes per post ratio\n",
            "    \n",
            "    Returns {\"profile_id\": X, \"liked_by\": [], ...} if person has no posts.\n",
            "\n",
            "Example:\n",
            "    get_linkedin_interactions(456)\n",
            "    â†’ {\n",
            "        \"profile_id\": 456,\n",
            "        \"post_count\": 10,\n",
            "        \"total_likes\": 150,\n",
            "        \"liked_by\": [123, 124, 125],\n",
            "        \"engagement_score\": 15.0\n",
            "    }\n",
            "\n",
            "Use case:\n",
            "    Assess professional network strength and content engagement.\n",
            "    Verify connections to claimed colleagues or industry peers.\n",
            "{'person_id': {'type': 'integer'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A simple agent using tools from the MCP server\n"
      ],
      "metadata": {
        "id": "ABoe2-qfXl7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
        "\n",
        "# ---------------------------\n",
        "# 1. Define a local tool\n",
        "# ---------------------------\n",
        "@tool\n",
        "def say_hello(name: str) -> str:\n",
        "    \"\"\"Say hello to a person by name.\"\"\"\n",
        "    return f\"Hello, {name}! ğŸ‘‹\"\n",
        "\n",
        "# ---------------------------\n",
        "# 2. Load MCP tools + merge\n",
        "# ---------------------------\n",
        "client = MultiServerMCPClient({\n",
        "    \"social_graph\": {\n",
        "        \"transport\": \"http\",\n",
        "        \"url\": \"https://ftec5660.ngrok.app/mcp\",\n",
        "        \"headers\": {\"ngrok-skip-browser-warning\": \"true\"}\n",
        "    }\n",
        "})\n",
        "\n",
        "mcp_tools = await client.get_tools()\n",
        "tools = mcp_tools + [say_hello]\n",
        "\n",
        "# ---------------------------\n",
        "# 3. Initialize Gemini (tool-enabled) or deepseek\n",
        "# ---------------------------\n",
        "# llm = ChatGoogleGenerativeAI(\n",
        "#     model=\"gemini-2.0-flash\",\n",
        "#     google_api_key=GEMINI_VERTEX_API_KEY,\n",
        "#     temperature=0,\n",
        "#     vertexai=True\n",
        "# )\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "DEEPSEEK_API_KEY = userdata.get('DEEPSEEK_API_KEY').strip()\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    base_url='https://ark.cn-beijing.volces.com/api/v3',\n",
        "    api_key=DEEPSEEK_API_KEY,\n",
        "\n",
        "    model=\"ep-20260226144712-mkcds\",\n",
        "\n",
        "    temperature=0,\n",
        "    request_timeout=30\n",
        ")\n",
        "\n",
        "\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "# ---------------------------\n",
        "# 4. Single-step invocation\n",
        "# ---------------------------\n",
        "query = \"Say hello to Bao using tool, then search for someone named Alice on Facebook.\"\n",
        "\n",
        "response = llm_with_tools.invoke([\n",
        "    HumanMessage(content=query)\n",
        "])\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtTjwFKhTKn3",
        "outputId": "4b7755e1-51f4-4cab-98d8-e535ff3c081b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content=\"I'll help you with that. First, let me say hello to Bao, and then search for Alice on Facebook.\\n\\n\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 68, 'prompt_tokens': 3189, 'total_tokens': 3257, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'deepseek-v3-2-251201', 'system_fingerprint': None, 'id': '021772089971834c43ef1438ef9a7261de2913935648484c728b4', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='lc_run--019c98cb-0ac8-7390-9c5c-9b9ebd6fd655-0' tool_calls=[{'name': 'say_hello', 'args': {'name': 'Bao'}, 'id': 'call_zd6twefhupp0bhgp1y4dgylr', 'type': 'tool_call'}] invalid_tool_calls=[] usage_metadata={'input_tokens': 3189, 'output_tokens': 68, 'total_tokens': 3257, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This block provides you some tests to get faminilar with our MCP server\n",
        "\n",
        "# # Test 1: Search Facebook users (exact match)\n",
        "# await tools[0].ainvoke({'q': \"Alex Chan\", 'limit': 5})\n",
        "\n",
        "# # Test 2: Search Facebook users (fuzzy match with typo)\n",
        "# await tools[0].ainvoke({'q': \"Alx Chn\", 'limit': 5, 'fuzzy': True})\n",
        "\n",
        "# # Test 3: Get Facebook profile\n",
        "# await tools[1].ainvoke({'user_id': 123})\n",
        "\n",
        "# # Test 4: Get Facebook mutual friends\n",
        "# await tools[2].ainvoke({'user_id_1': 123, 'user_id_2': 456})\n",
        "\n",
        "# # Test 5: Search LinkedIn people (exact match)\n",
        "# await tools[3].ainvoke({'q': \"Python\", 'location': \"Hong Kong\", 'limit': 5})\n",
        "\n",
        "# # Test 6: Search LinkedIn people (fuzzy match with typo)\n",
        "# await tools[3].ainvoke({'q': \"Python\", 'location': \"Hong Kong\", 'limit': 5, 'fuzzy': True})\n",
        "\n",
        "# # Test 7: Get LinkedIn profile\n",
        "# await tools[4].ainvoke({'person_id': 456})\n",
        "\n",
        "# Test 8: Get LinkedIn interactions\n",
        "await tools[5].ainvoke({'person_id': 456})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhLeoXGrqesW",
        "outputId": "f41572ca-0528-4efa-c9b4-9b0bd8acbdb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'type': 'text',\n",
              "  'text': '{\"profile_id\":456,\"post_count\":4,\"total_likes\":5,\"liked_by\":[4390,3622,7500,4269,8464],\"engagement_score\":1.25}',\n",
              "  'id': 'lc_cf7cf5a1-dc1c-470e-b927-19d225e687f5'}]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test2"
      ],
      "metadata": {
        "id": "9_FM0Iu06Mcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import asyncio\n",
        "from typing import Dict, Any, List\n",
        "\n",
        "# =====================================================\n",
        "#  Agent-style flow (LangGraph-like): Search â†’ Select â†’ Judge â†’ Aggregate â†’ Final\n",
        "# =====================================================\n",
        "\n",
        "# ---------------------------\n",
        "# 1) Tool mapping (name-agnostic)\n",
        "# ---------------------------\n",
        "\n",
        "def _pick_tool(tools, hints):\n",
        "    for h in hints:\n",
        "        for t in tools:\n",
        "            name = getattr(t, \"name\", \"\").lower()\n",
        "            if h in name:\n",
        "                return t\n",
        "    return None\n",
        "\n",
        "fb_search_tool = _pick_tool(tools, [\"facebook\", \"fb\", \"search\"]) or tools[0]\n",
        "fb_profile_tool = _pick_tool(tools, [\"facebook_profile\", \"fb_profile\", \"profile\"]) or tools[1]\n",
        "fb_mutual_tool = _pick_tool(tools, [\"mutual\", \"friends\"]) or tools[2]\n",
        "li_search_tool = _pick_tool(tools, [\"linkedin\", \"li\", \"search\"]) or tools[3]\n",
        "li_profile_tool = _pick_tool(tools, [\"linkedin_profile\", \"li_profile\", \"profile\"]) or tools[4]\n",
        "li_interact_tool = _pick_tool(tools, [\"interaction\", \"interactions\"]) or tools[5]\n",
        "\n",
        "# ---------------------------\n",
        "# 2) Text preprocessing / extraction\n",
        "# ---------------------------\n",
        "EMAIL_RE = re.compile(r\"[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,}\", re.I)\n",
        "PHONE_RE = re.compile(r\"(\\+?\\d[\\d\\s().-]{7,}\\d)\")\n",
        "\n",
        "EXTRACT_PROMPT = \"\"\"\n",
        "You are a hiring risk-control assistant. Extract the following fields from the resume and output JSON:\n",
        "- name (string, empty if missing)\n",
        "- current_title (string, empty if missing)\n",
        "- locations (array, may contain multiple locations)\n",
        "- companies (array, up to 6)\n",
        "- schools (array, up to 6)\n",
        "- skills (array, up to 10)\n",
        "- experience (array, each item includes company/title/start_year/end_year; can be null)\n",
        "- education (array, each item includes school/degree/start_year/end_year; can be null)\n",
        "\n",
        "Output JSON only. No explanations.\n",
        "Resume:\n",
        "{cv_text}\n",
        "\"\"\"\n",
        "\n",
        "def _safe_json(text: str) -> Dict[str, Any]:\n",
        "    m = re.search(r\"\\{[\\s\\S]*\\}\", text)\n",
        "    if not m:\n",
        "        return {}\n",
        "    try:\n",
        "        import json\n",
        "        return json.loads(m.group(0))\n",
        "    except Exception:\n",
        "        return {}\n",
        "\n",
        "\n",
        "def _ensure_list(x) -> List[Any]:\n",
        "    if not x:\n",
        "        return []\n",
        "    if isinstance(x, list):\n",
        "        return x\n",
        "    return [x]\n",
        "\n",
        "\n",
        "def _clean_list(items: List[Any]) -> List[str]:\n",
        "    seen = set()\n",
        "    out = []\n",
        "    for it in items:\n",
        "        s = str(it).strip()\n",
        "        if not s:\n",
        "            continue\n",
        "        key = re.sub(r\"\\s+\", \" \", s.lower())\n",
        "        if key in seen:\n",
        "            continue\n",
        "        seen.add(key)\n",
        "        out.append(s)\n",
        "    return out\n",
        "\n",
        "\n",
        "def _split_locations(loc: str) -> List[str]:\n",
        "    if not loc:\n",
        "        return []\n",
        "    s = loc.strip()\n",
        "    parts = re.split(r\"\\s*(?:/|;|ï¼›|\\||ã€|\\bor\\b|\\band\\b|&)\\s*\", s, flags=re.I)\n",
        "    parts = [p for p in parts if p and p.strip()]\n",
        "    return parts if parts else [s]\n",
        "\n",
        "\n",
        "def _fallback_name(cv_text: str) -> str:\n",
        "    for line in cv_text.splitlines():\n",
        "        s = line.strip()\n",
        "        if not s:\n",
        "            continue\n",
        "        if len(s) > 60:\n",
        "            continue\n",
        "        if re.search(r\"\\b(curriculum|resume|cv)\\b\", s, re.I):\n",
        "            continue\n",
        "        if re.search(r\"@|\\d\", s):\n",
        "            continue\n",
        "        if len(re.findall(r\"[A-Za-z\\u4e00-\\u9fff]\", s)) < 2:\n",
        "            continue\n",
        "        return s\n",
        "    return \"\"\n",
        "\n",
        "\n",
        "def _find_locations_fallback(cv_text: str) -> List[str]:\n",
        "    locs = []\n",
        "    for line in cv_text.splitlines()[:20]:\n",
        "        if \",\" in line and len(line) < 60:\n",
        "            if re.search(r\"[A-Za-z\\u4e00-\\u9fff]\", line):\n",
        "                locs.append(line.strip())\n",
        "    return _clean_list(locs)\n",
        "\n",
        "\n",
        "def extract_fields(cv_text: str) -> Dict[str, Any]:\n",
        "    emails = EMAIL_RE.findall(cv_text)[:3]\n",
        "    phones = PHONE_RE.findall(cv_text)[:3]\n",
        "\n",
        "    resp = llm.invoke(EXTRACT_PROMPT.format(cv_text=cv_text[:8000]))\n",
        "    data = _safe_json(getattr(resp, \"content\", \"\"))\n",
        "    data = data if isinstance(data, dict) else {}\n",
        "\n",
        "    data[\"name\"] = (data.get(\"name\") or \"\").strip()\n",
        "    data[\"current_title\"] = (data.get(\"current_title\") or \"\").strip()\n",
        "    data[\"locations\"] = _clean_list(_ensure_list(data.get(\"locations\")))\n",
        "    data[\"companies\"] = _clean_list(_ensure_list(data.get(\"companies\")))\n",
        "    data[\"schools\"] = _clean_list(_ensure_list(data.get(\"schools\")))\n",
        "    data[\"skills\"] = _clean_list(_ensure_list(data.get(\"skills\")))\n",
        "    data[\"experience\"] = _ensure_list(data.get(\"experience\"))\n",
        "    data[\"education\"] = _ensure_list(data.get(\"education\"))\n",
        "\n",
        "    if not data[\"name\"]:\n",
        "        data[\"name\"] = _fallback_name(cv_text)\n",
        "\n",
        "    if not data[\"locations\"]:\n",
        "        data[\"locations\"] = _find_locations_fallback(cv_text)\n",
        "\n",
        "    if len(data[\"locations\"]) == 1:\n",
        "        data[\"locations\"] = _clean_list(_split_locations(data[\"locations\"][0]))\n",
        "\n",
        "    data[\"emails\"] = _clean_list(emails)\n",
        "    data[\"phones\"] = _clean_list(phones)\n",
        "\n",
        "    return data\n",
        "\n",
        "# ---------------------------\n",
        "# 3) MCP response parsing (text/json)\n",
        "# ---------------------------\n",
        "\n",
        "def _unwrap_candidates(raw):\n",
        "    if isinstance(raw, list) and raw:\n",
        "        first = raw[0]\n",
        "        if isinstance(first, dict) and \"text\" in first:\n",
        "            try:\n",
        "                import json\n",
        "                return json.loads(first[\"text\"])\n",
        "            except Exception:\n",
        "                return []\n",
        "    return raw if isinstance(raw, list) else []\n",
        "\n",
        "\n",
        "def _unwrap_profile(raw):\n",
        "    if isinstance(raw, list) and raw:\n",
        "        first = raw[0]\n",
        "        if isinstance(first, dict) and \"text\" in first:\n",
        "            try:\n",
        "                import json\n",
        "                return json.loads(first[\"text\"])\n",
        "            except Exception:\n",
        "                return {}\n",
        "        if isinstance(first, dict):\n",
        "            return first\n",
        "    if isinstance(raw, dict):\n",
        "        return raw\n",
        "    return {}\n",
        "\n",
        "# ---------------------------\n",
        "# 4) Lightweight similarity (candidate ranking only)\n",
        "# ---------------------------\n",
        "\n",
        "def _norm(s: str) -> str:\n",
        "    s = (s or \"\").lower().strip()\n",
        "    s = re.sub(r\"[\\u2010-\\u2015]\", \"-\", s)\n",
        "    s = re.sub(r\"[^a-z0-9\\u4e00-\\u9fff\\s-]\", \" \", s)\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    return s\n",
        "\n",
        "\n",
        "def _tokens(s: str) -> List[str]:\n",
        "    return re.findall(r\"[a-z0-9\\u4e00-\\u9fff]+\", _norm(s))\n",
        "\n",
        "\n",
        "def _string_sim(a: str, b: str) -> float:\n",
        "    a = _norm(a)\n",
        "    b = _norm(b)\n",
        "    if not a or not b:\n",
        "        return 0.0\n",
        "    if a == b:\n",
        "        return 1.0\n",
        "    if a in b or b in a:\n",
        "        return 0.9\n",
        "    ta = set(_tokens(a))\n",
        "    tb = set(_tokens(b))\n",
        "    if not ta or not tb:\n",
        "        return 0.0\n",
        "    inter = len(ta & tb)\n",
        "    union = len(ta | tb)\n",
        "    return inter / union if union else 0.0\n",
        "\n",
        "\n",
        "def _max_sim_in_list(items: List[str], target: str) -> float:\n",
        "    if not items or not target:\n",
        "        return 0.0\n",
        "    return max((_string_sim(it, target) for it in items), default=0.0)\n",
        "\n",
        "\n",
        "def _as_int(x):\n",
        "    try:\n",
        "        return int(x)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "def _dedupe_candidates(cands: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
        "    seen = set()\n",
        "    out = []\n",
        "    for c in cands:\n",
        "        cid = c.get(\"id\") or c.get(\"person_id\") or c.get(\"user_id\")\n",
        "        key = str(cid) if cid is not None else _norm(c.get(\"name\") or c.get(\"display_name\") or \"\")\n",
        "        if not key or key in seen:\n",
        "            continue\n",
        "        seen.add(key)\n",
        "        out.append(c)\n",
        "    return out\n",
        "\n",
        "# ---------------------------\n",
        "# 5) Node: Search\n",
        "# ---------------------------\n",
        "\n",
        "async def node_search(fields: Dict[str, Any], log: bool = False) -> Dict[str, Any]:\n",
        "    name = (fields.get(\"name\") or \"\").strip()\n",
        "    locations = fields.get(\"locations\", [])\n",
        "\n",
        "    li_cands = []\n",
        "    fb_cands = []\n",
        "\n",
        "    if name:\n",
        "        loc_queries = locations if locations else [None]\n",
        "\n",
        "        # Two-pass recall: exact first, then fuzzy.\n",
        "        for loc in loc_queries:\n",
        "            for fuzzy in (False, True):\n",
        "                payload = {\n",
        "                    \"q\": name,\n",
        "                    \"limit\": 20,\n",
        "                    \"fuzzy\": fuzzy,\n",
        "                }\n",
        "                if loc:\n",
        "                    payload[\"location\"] = loc\n",
        "                raw = await li_search_tool.ainvoke(payload)\n",
        "                li_cands += _unwrap_candidates(raw)\n",
        "\n",
        "        if not li_cands:\n",
        "            raw = await li_search_tool.ainvoke({\"q\": name, \"limit\": 20, \"fuzzy\": True})\n",
        "            li_cands += _unwrap_candidates(raw)\n",
        "\n",
        "        for fuzzy in (False, True):\n",
        "            raw = await fb_search_tool.ainvoke({\"q\": name, \"limit\": 20, \"fuzzy\": fuzzy})\n",
        "            fb_cands += _unwrap_candidates(raw)\n",
        "\n",
        "    li_cands = _dedupe_candidates(li_cands)\n",
        "    fb_cands = _dedupe_candidates(fb_cands)\n",
        "\n",
        "    if log:\n",
        "        print(\"[Node: Search] LinkedIn candidates:\", li_cands)\n",
        "        print(\"[Node: Search] Facebook candidates:\", fb_cands)\n",
        "\n",
        "    return {\"li_candidates\": li_cands, \"fb_candidates\": fb_cands}\n",
        "\n",
        "# ---------------------------\n",
        "# 6) Node: Select (Top 3)\n",
        "# ---------------------------\n",
        "\n",
        "# ---------------------------\n",
        "# 6) Node: Select (Top 3)\n",
        "# ---------------------------\n",
        "\n",
        "async def node_select(fields: Dict[str, Any], search_out: Dict[str, Any], log: bool = False) -> Dict[str, Any]:\n",
        "    name = fields.get(\"name\", \"\")\n",
        "    locations = fields.get(\"locations\", [])\n",
        "    title = fields.get(\"current_title\", \"\")\n",
        "    companies = fields.get(\"companies\", [])\n",
        "    schools = fields.get(\"schools\", [])\n",
        "\n",
        "    def li_rank(c):\n",
        "        name_score = _string_sim(name, c.get(\"name\", \"\"))\n",
        "        loc_score = _string_sim(\", \".join(locations), c.get(\"location\", \"\"))\n",
        "        headline = c.get(\"headline\", \"\")\n",
        "        title_score = _string_sim(title, headline)\n",
        "        company_score = _max_sim_in_list(companies, headline)\n",
        "        school_score = _max_sim_in_list(schools, headline)\n",
        "        exact_bonus = 0.05 if str(c.get(\"match_type\", \"\")).lower() == \"exact\" else 0.0\n",
        "        return 0.45 * name_score + 0.2 * loc_score + 0.2 * title_score + 0.1 * company_score + 0.05 * school_score + exact_bonus\n",
        "\n",
        "    def fb_rank(c):\n",
        "        loc_text = f\"{c.get('city','')}, {c.get('country','')}\"\n",
        "        name_score = _string_sim(name, c.get(\"display_name\", \"\"))\n",
        "        loc_score = _string_sim(\", \".join(locations), loc_text)\n",
        "        exact_bonus = 0.05 if str(c.get(\"match_type\", \"\")).lower() == \"exact\" else 0.0\n",
        "        return 0.75 * name_score + 0.25 * loc_score + exact_bonus\n",
        "\n",
        "    li_top = sorted(search_out.get(\"li_candidates\", []), key=li_rank, reverse=True)[:3]\n",
        "    fb_top = sorted(search_out.get(\"fb_candidates\", []), key=fb_rank, reverse=True)[:3]\n",
        "\n",
        "    if log:\n",
        "        print(\"[Node: Select] LinkedIn top-3:\", li_top)\n",
        "        print(\"[Node: Select] Facebook top-3:\", fb_top)\n",
        "\n",
        "    return {\"li_top\": li_top, \"fb_top\": fb_top}\n",
        "\n",
        "# ---------------------------\n",
        "# 7) Node: Judge (LLM)\n",
        "# ---------------------------\n",
        "\n",
        "# ---------------------------\n",
        "# 7) Node: Judge (LLM)\n",
        "# ---------------------------\n",
        "\n",
        "LLM_MATCH_PROMPT = \"\"\"\n",
        "You are an identity-matching assistant. Decide whether the resume and the platform profile refer to the same person.\n",
        "\n",
        "Notes:\n",
        "- Do not use dynamic content (e.g., Facebook posts or friends) as evidence.\n",
        "- Hong Kong may appear as a city or as a country; interpret location flexibly.\n",
        "- Name/location are weak signals and can be ambiguous.\n",
        "- Company/school/industry/title/skills alignment are strong signals; if those conflict, be cautious.\n",
        "- If only weak signals exist, return unknown or low confidence.\n",
        "\n",
        "Output JSON only:\n",
        "{{\n",
        "  \"match\": \"yes\" | \"no\" | \"unknown\",\n",
        "  \"confidence\": 0~1,\n",
        "  \"reasons\": [\"short reason 1\", \"short reason 2\"]\n",
        "}}\n",
        "\n",
        "Resume summary:\n",
        "{cv_summary}\n",
        "\n",
        "Candidate profile ({source}):\n",
        "{profile_summary}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def _llm_json(text: str) -> Dict[str, Any]:\n",
        "    m = re.search(r\"\\{[\\s\\S]*\\}\", text)\n",
        "    if not m:\n",
        "        return {}\n",
        "    try:\n",
        "        import json\n",
        "        return json.loads(m.group(0))\n",
        "    except Exception:\n",
        "        return {}\n",
        "\n",
        "\n",
        "def _cv_summary(fields: Dict[str, Any]) -> str:\n",
        "    exp = fields.get(\"experience\", [])[:3]\n",
        "    edu = fields.get(\"education\", [])[:2]\n",
        "    return (\n",
        "        f\"name: {fields.get('name','')}\\n\"\n",
        "        f\"title: {fields.get('current_title','')}\\n\"\n",
        "        f\"locations: {fields.get('locations',[])}\\n\"\n",
        "        f\"companies: {fields.get('companies',[])}\\n\"\n",
        "        f\"schools: {fields.get('schools',[])}\\n\"\n",
        "        f\"skills: {fields.get('skills',[])}\\n\"\n",
        "        f\"experience: {exp}\\n\"\n",
        "        f\"education: {edu}\\n\"\n",
        "    )\n",
        "\n",
        "\n",
        "def _li_summary(profile: Dict[str, Any]) -> str:\n",
        "    exp = profile.get(\"experience\", [])[:4]\n",
        "    edu = profile.get(\"education\", [])[:2]\n",
        "    skills = [s.get(\"name\") for s in profile.get(\"skills\", []) if s.get(\"name\")][:8]\n",
        "    return (\n",
        "        f\"name: {profile.get('name','')}\\n\"\n",
        "        f\"headline: {profile.get('headline','')}\\n\"\n",
        "        f\"location: {profile.get('city','')}, {profile.get('country','')}\\n\"\n",
        "        f\"industry: {profile.get('industry','')}\\n\"\n",
        "        f\"experience: {exp}\\n\"\n",
        "        f\"education: {edu}\\n\"\n",
        "        f\"skills: {skills}\\n\"\n",
        "    )\n",
        "\n",
        "\n",
        "def _fb_summary(profile: Dict[str, Any]) -> str:\n",
        "    # Ignore posts/friends and other dynamic noise\n",
        "    return (\n",
        "        f\"display_name: {profile.get('display_name','')}\\n\"\n",
        "        f\"original_name: {profile.get('original_name','')}\\n\"\n",
        "        f\"location: {profile.get('city','')}, {profile.get('country','')}\\n\"\n",
        "        f\"current_company: {profile.get('current_company','')}\\n\"\n",
        "        f\"current_job: {profile.get('current_job','')}\\n\"\n",
        "        f\"education: {profile.get('education','')}\\n\"\n",
        "        f\"bio: {profile.get('bio','')}\\n\"\n",
        "    )\n",
        "\n",
        "\n",
        "def _llm_match(cv_summary: str, profile_summary: str, source: str) -> Dict[str, Any]:\n",
        "    prompt = LLM_MATCH_PROMPT.format(\n",
        "        cv_summary=cv_summary,\n",
        "        profile_summary=profile_summary,\n",
        "        source=source,\n",
        "    )\n",
        "    resp = llm.invoke(prompt)\n",
        "    data = _llm_json(getattr(resp, \"content\", \"\"))\n",
        "    match = data.get(\"match\", \"unknown\")\n",
        "    conf = data.get(\"confidence\", 0.0)\n",
        "    reasons = data.get(\"reasons\", [])\n",
        "    return {\n",
        "        \"match\": match if match in [\"yes\", \"no\", \"unknown\"] else \"unknown\",\n",
        "        \"confidence\": float(conf) if isinstance(conf, (int, float)) else 0.0,\n",
        "        \"reasons\": reasons if isinstance(reasons, list) else [],\n",
        "    }\n",
        "\n",
        "\n",
        "def _llm_score_from_match(m: Dict[str, Any]) -> float:\n",
        "    match = m.get(\"match\", \"unknown\")\n",
        "    conf = max(0.0, min(1.0, m.get(\"confidence\", 0.0)))\n",
        "    if match == \"yes\":\n",
        "        return 0.65 + 0.35 * conf\n",
        "    if match == \"no\":\n",
        "        return 0.05 + 0.25 * (1.0 - conf)\n",
        "    # Unknown keeps moderate score; final decision is made in node_final.\n",
        "    return 0.40 + 0.25 * conf\n",
        "\n",
        "\n",
        "async def node_judge(fields: Dict[str, Any], select_out: Dict[str, Any], log: bool = False) -> Dict[str, Any]:\n",
        "    cv_summary = _cv_summary(fields)\n",
        "\n",
        "    li_matches = []\n",
        "    for cand in select_out.get(\"li_top\", []):\n",
        "        li_id = cand.get(\"id\") or cand.get(\"person_id\")\n",
        "        li_id_int = _as_int(li_id)\n",
        "        if li_id_int is None:\n",
        "            continue\n",
        "        raw = await li_profile_tool.ainvoke({\"person_id\": li_id_int})\n",
        "        profile = _unwrap_profile(raw)\n",
        "        if not profile:\n",
        "            continue\n",
        "        m = _llm_match(cv_summary, _li_summary(profile), \"LinkedIn\")\n",
        "        li_matches.append({\n",
        "            \"candidate\": cand,\n",
        "            \"profile\": profile,\n",
        "            \"match\": m[\"match\"],\n",
        "            \"confidence\": m[\"confidence\"],\n",
        "            \"reasons\": m.get(\"reasons\", []),\n",
        "            \"score\": _llm_score_from_match(m),\n",
        "        })\n",
        "\n",
        "    fb_matches = []\n",
        "    for cand in select_out.get(\"fb_top\", []):\n",
        "        fb_id = cand.get(\"id\") or cand.get(\"user_id\")\n",
        "        fb_id_int = _as_int(fb_id)\n",
        "        if fb_id_int is None:\n",
        "            continue\n",
        "        raw = await fb_profile_tool.ainvoke({\"user_id\": fb_id_int})\n",
        "        profile = _unwrap_profile(raw)\n",
        "        if not profile:\n",
        "            continue\n",
        "        m = _llm_match(cv_summary, _fb_summary(profile), \"Facebook\")\n",
        "        fb_matches.append({\n",
        "            \"candidate\": cand,\n",
        "            \"profile\": profile,\n",
        "            \"match\": m[\"match\"],\n",
        "            \"confidence\": m[\"confidence\"],\n",
        "            \"reasons\": m.get(\"reasons\", []),\n",
        "            \"score\": _llm_score_from_match(m),\n",
        "        })\n",
        "\n",
        "    if log:\n",
        "        print(\"[Node: Judge] LinkedIn judgments:\", [{\"match\": m[\"match\"], \"confidence\": m[\"confidence\"], \"candidate\": m[\"candidate\"]} for m in li_matches])\n",
        "        print(\"[Node: Judge] Facebook judgments:\", [{\"match\": m[\"match\"], \"confidence\": m[\"confidence\"], \"candidate\": m[\"candidate\"]} for m in fb_matches])\n",
        "\n",
        "    return {\"li_matches\": li_matches, \"fb_matches\": fb_matches}\n",
        "\n",
        "# ---------------------------\n",
        "# 8) Node: Aggregate\n",
        "# ---------------------------\n",
        "\n",
        "def _aggregate(matches: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
        "    if not matches:\n",
        "        return {\"score\": 0.2, \"verdict\": \"unknown\", \"matches\": []}\n",
        "\n",
        "    yes = [m for m in matches if m.get(\"match\") == \"yes\"]\n",
        "    unknown = [m for m in matches if m.get(\"match\") == \"unknown\"]\n",
        "    no = [m for m in matches if m.get(\"match\") == \"no\"]\n",
        "\n",
        "    if yes:\n",
        "        best_yes = max(yes, key=lambda m: (m.get(\"confidence\", 0.0), m.get(\"score\", 0.0)))\n",
        "        return {\n",
        "            \"score\": max(0.55, best_yes.get(\"score\", 0.65)),\n",
        "            \"verdict\": \"yes\",\n",
        "            \"matches\": matches,\n",
        "            \"best\": best_yes,\n",
        "        }\n",
        "\n",
        "    if unknown:\n",
        "        best_unk = max(unknown, key=lambda m: (m.get(\"confidence\", 0.0), m.get(\"score\", 0.0)))\n",
        "        conf = best_unk.get(\"confidence\", 0.0)\n",
        "        score = max(0.40, min(0.65, best_unk.get(\"score\", 0.45)))\n",
        "        if conf >= 0.80:\n",
        "            return {\n",
        "                \"score\": max(0.55, score),\n",
        "                \"verdict\": \"yes\",\n",
        "                \"matches\": matches,\n",
        "                \"best\": best_unk,\n",
        "            }\n",
        "        return {\n",
        "            \"score\": score,\n",
        "            \"verdict\": \"unknown\",\n",
        "            \"matches\": matches,\n",
        "            \"best\": best_unk,\n",
        "        }\n",
        "\n",
        "    best_no = max(no, key=lambda m: (m.get(\"confidence\", 0.0), m.get(\"score\", 0.0))) if no else None\n",
        "    return {\"score\": best_no.get(\"score\", 0.2) if best_no else 0.2, \"verdict\": \"no\", \"matches\": matches, \"best\": best_no}\n",
        "\n",
        "\n",
        "def node_aggregate(judge_out: Dict[str, Any], log: bool = False) -> Dict[str, Any]:\n",
        "    li = _aggregate(judge_out.get(\"li_matches\", []))\n",
        "    fb = _aggregate(judge_out.get(\"fb_matches\", []))\n",
        "    if log:\n",
        "        print(\"[Node: Aggregate] LinkedIn:\", {\"score\": li[\"score\"], \"verdict\": li[\"verdict\"]})\n",
        "        print(\"[Node: Aggregate] Facebook:\", {\"score\": fb[\"score\"], \"verdict\": fb[\"verdict\"]})\n",
        "    return {\"li\": li, \"fb\": fb}\n",
        "\n",
        "# ---------------------------\n",
        "# 9) Node: Final\n",
        "# ---------------------------\n",
        "\n",
        "def node_final(agg_out: Dict[str, Any], log: bool = False) -> Dict[str, Any]:\n",
        "    li = agg_out.get(\"li\", {})\n",
        "    fb = agg_out.get(\"fb\", {})\n",
        "\n",
        "    li_verdict = li.get(\"verdict\")\n",
        "    fb_verdict = fb.get(\"verdict\")\n",
        "    li_score = max(0.0, min(1.0, li.get(\"score\", 0.2)))\n",
        "    fb_score = max(0.0, min(1.0, fb.get(\"score\", 0.2)))\n",
        "\n",
        "    # Simple decision fusion: LinkedIn is primary, Facebook is supportive.\n",
        "    if li_verdict == \"yes\" and fb_verdict == \"yes\":\n",
        "        score = min(1.0, max(li_score, fb_score) + 0.02)\n",
        "    elif li_verdict == \"yes\":\n",
        "        score = min(1.0, li_score * 0.98 + (0.02 if fb_verdict in [\"yes\", \"unknown\"] else 0.0))\n",
        "    elif fb_verdict == \"yes\":\n",
        "        score = fb_score * 0.92\n",
        "    elif li_verdict == \"unknown\" or fb_verdict == \"unknown\":\n",
        "        score = max(li_score, fb_score * 0.95)\n",
        "    else:\n",
        "        score = 0.2\n",
        "\n",
        "    score = max(0.0, min(1.0, score))\n",
        "    verdict = \"yes\" if score > 0.5 else \"no\"\n",
        "\n",
        "    if log:\n",
        "        print(\"[Node: Final] score=\", score, \"verdict=\", verdict)\n",
        "\n",
        "    return {\"score\": score, \"verdict\": verdict}\n",
        "\n",
        "# ---------------------------\n",
        "# 10) Agent run\n",
        "# ---------------------------\n",
        "\n",
        "# ---------------------------\n",
        "# 10) Agent run\n",
        "# ---------------------------\n",
        "\n",
        "async def run_agent(cv_text: str, log: bool = True) -> Dict[str, Any]:\n",
        "    fields = extract_fields(cv_text)\n",
        "    if log:\n",
        "        print(\"[Node: Extract] fields=\", fields)\n",
        "\n",
        "    search_out = await node_search(fields, log=log)\n",
        "    select_out = await node_select(fields, search_out, log=log)\n",
        "    judge_out = await node_judge(fields, select_out, log=log)\n",
        "    agg_out = node_aggregate(judge_out, log=log)\n",
        "    final_out = node_final(agg_out, log=log)\n",
        "\n",
        "    return {\n",
        "        \"fields\": fields,\n",
        "        \"search\": search_out,\n",
        "        \"select\": select_out,\n",
        "        \"judge\": judge_out,\n",
        "        \"aggregate\": agg_out,\n",
        "        \"final\": final_out,\n",
        "    }\n",
        "\n",
        "# ---------------------------\n",
        "# 11) Public API\n",
        "# ---------------------------\n",
        "\n",
        "async def score_cv(cv_text: str) -> Dict[str, Any]:\n",
        "    result = await run_agent(cv_text, log=False)\n",
        "    return {\n",
        "        \"score\": result[\"final\"][\"score\"],\n",
        "        \"fields\": result[\"fields\"],\n",
        "        \"li_result\": result[\"aggregate\"][\"li\"],\n",
        "        \"fb_result\": result[\"aggregate\"][\"fb\"],\n",
        "    }\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 12) Batch scoring\n",
        "# ---------------------------\n",
        "\n",
        "def _brief_li(c):\n",
        "    return {\n",
        "        \"id\": c.get(\"id\"),\n",
        "        \"name\": c.get(\"name\"),\n",
        "        \"location\": c.get(\"location\"),\n",
        "        \"match_type\": c.get(\"match_type\"),\n",
        "    }\n",
        "\n",
        "\n",
        "def _brief_fb(c):\n",
        "    return {\n",
        "        \"id\": c.get(\"id\"),\n",
        "        \"name\": c.get(\"display_name\"),\n",
        "        \"location\": f\"{c.get('city', '')}, {c.get('country', '')}\",\n",
        "        \"match_type\": c.get(\"match_type\"),\n",
        "    }\n",
        "\n",
        "\n",
        "async def score_all_cvs(all_cvs, debug: bool = False):\n",
        "    results = []\n",
        "    for item in all_cvs:\n",
        "        if debug:\n",
        "            full = await run_agent(item[\"text\"], log=False)\n",
        "            res = {\n",
        "                \"score\": full[\"final\"][\"score\"],\n",
        "                \"fields\": full[\"fields\"],\n",
        "                \"li_result\": full[\"aggregate\"][\"li\"],\n",
        "                \"fb_result\": full[\"aggregate\"][\"fb\"],\n",
        "            }\n",
        "\n",
        "            print(\"\\n\" + \"=\" * 90)\n",
        "            print(\"[DEBUG]\", item[\"file\"])\n",
        "            print(\"[Extract]\", {\n",
        "                \"name\": full[\"fields\"].get(\"name\"),\n",
        "                \"title\": full[\"fields\"].get(\"current_title\"),\n",
        "                \"locations\": full[\"fields\"].get(\"locations\"),\n",
        "                \"companies\": full[\"fields\"].get(\"companies\", [])[:3],\n",
        "                \"schools\": full[\"fields\"].get(\"schools\", [])[:3],\n",
        "            })\n",
        "            print(\"[Select-LI]\", [_brief_li(x) for x in full[\"select\"].get(\"li_top\", [])])\n",
        "            print(\"[Select-FB]\", [_brief_fb(x) for x in full[\"select\"].get(\"fb_top\", [])])\n",
        "            print(\"[Judge-LI]\", [\n",
        "                {\"match\": m.get(\"match\"), \"confidence\": m.get(\"confidence\"), \"candidate\": _brief_li(m.get(\"candidate\", {}))}\n",
        "                for m in full[\"judge\"].get(\"li_matches\", [])\n",
        "            ])\n",
        "            print(\"[Judge-FB]\", [\n",
        "                {\"match\": m.get(\"match\"), \"confidence\": m.get(\"confidence\"), \"candidate\": _brief_fb(m.get(\"candidate\", {}))}\n",
        "                for m in full[\"judge\"].get(\"fb_matches\", [])\n",
        "            ])\n",
        "            print(\"[Aggregate]\", full[\"aggregate\"])\n",
        "            print(\"[Final]\", full[\"final\"])\n",
        "        else:\n",
        "            res = await score_cv(item[\"text\"])\n",
        "\n",
        "        res[\"file\"] = item[\"file\"]\n",
        "        results.append(res)\n",
        "        print(item[\"file\"], \"=>\", res[\"score\"])\n",
        "\n",
        "    return results\n",
        "\n",
        "# Run and produce scores list\n",
        "results = await score_all_cvs(all_cvs, debug=True)\n",
        "scores = [r[\"score\"] for r in results]\n",
        "print(\"scores =\", scores)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1oELGGE6WVv",
        "outputId": "4c3663e5-3e72-440a-8ab4-97ca50cf506a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==========================================================================================\n",
            "[DEBUG] CV_1.pdf\n",
            "[Extract] {'name': 'John Smith', 'title': 'Marketing Professional', 'locations': ['Singapore, Singapore', 'Kowloon'], 'companies': ['ByteDance'], 'schools': ['McGill University']}\n",
            "[Select-LI] [{'id': 9603, 'name': 'John Smith', 'location': 'Kowloon, Hong Kong', 'match_type': 'exact'}, {'id': 8, 'name': 'John Smith', 'location': 'Kowloon, Hong Kong', 'match_type': 'exact'}, {'id': 2461, 'name': 'John Smith', 'location': 'Kowloon, Hong Kong', 'match_type': 'exact'}]\n",
            "[Select-FB] [{'id': 213, 'name': 'John Smith', 'location': 'Singapore, Singapore', 'match_type': 'exact'}, {'id': 335, 'name': 'John Smith', 'location': 'Singapore, Singapore', 'match_type': 'exact'}, {'id': 377, 'name': 'John Smith', 'location': 'Singapore, Singapore', 'match_type': 'exact'}]\n",
            "[Judge-LI] [{'match': 'no', 'confidence': 0.9, 'candidate': {'id': 9603, 'name': 'John Smith', 'location': 'Kowloon, Hong Kong', 'match_type': 'exact'}}, {'match': 'no', 'confidence': 0.9, 'candidate': {'id': 8, 'name': 'John Smith', 'location': 'Kowloon, Hong Kong', 'match_type': 'exact'}}, {'match': 'no', 'confidence': 0.9, 'candidate': {'id': 2461, 'name': 'John Smith', 'location': 'Kowloon, Hong Kong', 'match_type': 'exact'}}]\n",
            "[Judge-FB] [{'match': 'no', 'confidence': 0.9, 'candidate': {'id': 213, 'name': 'John Smith', 'location': 'Singapore, Singapore', 'match_type': 'exact'}}, {'match': 'no', 'confidence': 0.9, 'candidate': {'id': 335, 'name': 'John Smith', 'location': 'Singapore, Singapore', 'match_type': 'exact'}}, {'match': 'no', 'confidence': 0.2, 'candidate': {'id': 377, 'name': 'John Smith', 'location': 'Singapore, Singapore', 'match_type': 'exact'}}]\n",
            "[Aggregate] {'li': {'score': 0.075, 'verdict': 'no', 'matches': [{'candidate': {'id': 9603, 'name': 'John Smith', 'headline': 'Marketing Professional', 'industry': 'Marketing', 'location': 'Kowloon, Hong Kong', 'years_experience': 11, 'match_type': 'exact'}, 'profile': {'id': 9603, 'name': 'John Smith', 'headline': 'Marketing Professional', 'city': 'Kowloon', 'country': 'Hong Kong', 'industry': 'Marketing', 'status': 'open_to_work', 'years_experience': 11, 'summary': 'Particular night season increase put wife against. Other cover sign that. Investment expect old energy.', 'skills': [{'name': 'Advertising', 'proficiency': 1}, {'name': 'Social Media', 'proficiency': 2}, {'name': 'SEO', 'proficiency': 4}, {'name': 'Content Creation', 'proficiency': 3}], 'experience': [{'company': 'Meta', 'title': 'Scientist', 'seniority': 'junior', 'start_year': 2011, 'end_year': None, 'is_current': True}, {'company': 'Bright Solutions', 'title': 'Scientist', 'seniority': 'senior', 'start_year': 2017, 'end_year': 2019, 'is_current': True}], 'education': [{'school': 'Seoul National University', 'degree': 'BSc', 'field': 'Marketing', 'start_year': 2003, 'end_year': 2008}]}, 'match': 'no', 'confidence': 0.9, 'reasons': ['Major company conflict (ByteDance vs. Meta/Bright Solutions)', 'Major school conflict (McGill University vs. Seoul National University)', 'Title/role conflict (Engineer vs. Scientist)'], 'score': 0.075}, {'candidate': {'id': 8, 'name': 'John Smith', 'headline': 'Finance Professional', 'industry': 'Finance', 'location': 'Kowloon, Hong Kong', 'years_experience': 8, 'match_type': 'exact'}, 'profile': {'id': 8, 'name': 'John Smith', 'headline': 'Finance Professional', 'city': 'Kowloon', 'country': 'Hong Kong', 'industry': 'Finance', 'status': 'open_to_work', 'years_experience': 8, 'summary': 'Race think accept candidate majority consider. Prepare front exactly article. Help politics against full keep take. Radio chair start seat environmental left. Article billion large. While continue ok stage get manager pass.', 'skills': [{'name': 'Financial Analysis', 'proficiency': 3}, {'name': 'Excel', 'proficiency': 3}, {'name': 'Risk Modeling', 'proficiency': 1}], 'experience': [{'company': 'Hang Seng Bank', 'title': 'Engineer', 'seniority': 'senior', 'start_year': 2008, 'end_year': None, 'is_current': True}], 'education': [{'school': 'University of Sydney', 'degree': 'PhD', 'field': 'Finance', 'start_year': 2014, 'end_year': 2019}]}, 'match': 'no', 'confidence': 0.9, 'reasons': ['Strong conflict in companies (ByteDance vs Hang Seng Bank)', 'Strong conflict in education (McGill University vs University of Sydney)', 'Strong conflict in industry/skills (Marketing/Content Creation vs Finance/Financial Analysis)'], 'score': 0.075}, {'candidate': {'id': 2461, 'name': 'John Smith', 'headline': 'Logistics Professional', 'industry': 'Logistics', 'location': 'Kowloon, Hong Kong', 'years_experience': 15, 'match_type': 'exact'}, 'profile': {'id': 2461, 'name': 'John Smith', 'headline': 'Logistics Professional', 'city': 'Kowloon', 'country': 'Hong Kong', 'industry': 'Logistics', 'status': 'employed', 'years_experience': 15, 'summary': 'Language capital gas. Real international throughout worker position TV. Medical exactly fine themselves blood need game. Change now treatment to side.', 'skills': [{'name': 'Operations', 'proficiency': 3}, {'name': 'Supply Chain', 'proficiency': 3}, {'name': 'Inventory Management', 'proficiency': 3}], 'experience': [{'company': 'Grab', 'title': 'Engineer', 'seniority': 'mid', 'start_year': 2012, 'end_year': 2016, 'is_current': True}, {'company': 'Bright Solutions', 'title': 'Manager', 'seniority': 'senior', 'start_year': 2006, 'end_year': None, 'is_current': False}], 'education': [{'school': 'University of Toronto', 'degree': 'PhD', 'field': 'Logistics', 'start_year': 2013, 'end_year': 2016}]}, 'match': 'no', 'confidence': 0.9, 'reasons': ['Strong conflict in core professional identity: resume is Marketing (ByteDance, Content, SEO) vs profile is Logistics (Logistics industry, Supply Chain skills).', 'Strong conflict in education: resume shows McGill University (Marketing degree) vs profile shows University of Toronto (PhD in Logistics).', 'Strong conflict in work history: resume shows current role at ByteDance (2020-Present) vs profile shows current role at Grab (2012-2016) and no ByteDance experience.'], 'score': 0.075}], 'best': {'candidate': {'id': 9603, 'name': 'John Smith', 'headline': 'Marketing Professional', 'industry': 'Marketing', 'location': 'Kowloon, Hong Kong', 'years_experience': 11, 'match_type': 'exact'}, 'profile': {'id': 9603, 'name': 'John Smith', 'headline': 'Marketing Professional', 'city': 'Kowloon', 'country': 'Hong Kong', 'industry': 'Marketing', 'status': 'open_to_work', 'years_experience': 11, 'summary': 'Particular night season increase put wife against. Other cover sign that. Investment expect old energy.', 'skills': [{'name': 'Advertising', 'proficiency': 1}, {'name': 'Social Media', 'proficiency': 2}, {'name': 'SEO', 'proficiency': 4}, {'name': 'Content Creation', 'proficiency': 3}], 'experience': [{'company': 'Meta', 'title': 'Scientist', 'seniority': 'junior', 'start_year': 2011, 'end_year': None, 'is_current': True}, {'company': 'Bright Solutions', 'title': 'Scientist', 'seniority': 'senior', 'start_year': 2017, 'end_year': 2019, 'is_current': True}], 'education': [{'school': 'Seoul National University', 'degree': 'BSc', 'field': 'Marketing', 'start_year': 2003, 'end_year': 2008}]}, 'match': 'no', 'confidence': 0.9, 'reasons': ['Major company conflict (ByteDance vs. Meta/Bright Solutions)', 'Major school conflict (McGill University vs. Seoul National University)', 'Title/role conflict (Engineer vs. Scientist)'], 'score': 0.075}}, 'fb': {'score': 0.075, 'verdict': 'no', 'matches': [{'candidate': {'id': 213, 'display_name': 'John Smith', 'city': 'Singapore', 'country': 'Singapore', 'match_type': 'exact'}, 'profile': {'id': 213, 'display_name': 'John Smith', 'original_name': 'John Smith', 'city': 'Singapore', 'country': 'Singapore', 'hometown': 'Hong Kong', 'bio': 'Evidence ago much.  Amount travel find consumer door near president', 'status': 'Engaged', 'education': \"Bachelor's Degree\", 'current_job': 'Scientist', 'current_company': 'Traveloka', 'interests': 'Machine Learning, Reading, Cooking', 'friend_count': 34, 'friends': [205, 471, 9093, 2344, 247, 1738, 4778, 9391, 283, 368, 5105, 3283, 4022, 6903, 5177, 1755, 5628, 5629, 1075, 1636, 2271, 3616, 4956, 5196, 5592, 5836, 7124, 7201, 8027, 8355, 8577, 8733, 9176, 9770], 'posts': [{'id': 1199, 'content': 'New personal best in Machine Learning! Progress feels amazing ğŸ’ª'}, {'id': 1200, 'content': 'Late night ramen cravings = satisfied ğŸŒ®'}, {'id': 1201, 'content': 'Celebrating small wins today! ğŸŠ'}, {'id': 1202, 'content': 'Family dinner never gets old â¤ï¸ #blessed'}, {'id': 1203, 'content': \"Cousins gathering! Haven't seen everyone in ages! ğŸ‘¨\\u200dğŸ‘©\\u200dğŸ‘§\\u200dğŸ‘¦\"}]}, 'match': 'no', 'confidence': 0.9, 'reasons': ['Strong conflict in current company (ByteDance vs Traveloka)', 'Strong conflict in current job title (Engineer vs Scientist)'], 'score': 0.075}, {'candidate': {'id': 335, 'display_name': 'John Smith', 'city': 'Singapore', 'country': 'Singapore', 'match_type': 'exact'}, 'profile': {'id': 335, 'display_name': 'John Smith', 'original_name': 'John Smith', 'city': 'Singapore', 'country': 'Singapore', 'hometown': 'Hong Kong', 'bio': 'Rule unit many the production person.  Star chair cut American she knowledge', 'status': 'Married', 'education': 'Doctoral Degree', 'current_job': 'Scientist', 'current_company': 'Carousell', 'interests': 'Cycling, Operations Management, Piano', 'friend_count': 54, 'friends': [284, 8195, 8331, 7308, 6286, 2455, 1566, 165, 7974, 5415, 2986, 5548, 9904, 2482, 1463, 3262, 1747, 3798, 2523, 2524, 7517, 5348, 7911, 8167, 4587, 6256, 8177, 5746, 4724, 3319, 7548, 479, 547, 958, 1098, 1441, 1556, 3387, 3573, 4093, 4384, 4855, 4929, 5158, 5382, 5456, 5726, 5793, 6903, 7258, 7827, 8030, 8683, 8832], 'posts': [{'id': 1835, 'content': 'Road trip through Singapore. Best decision ever! ğŸš—'}, {'id': 1836, 'content': 'Career milestone unlocked! Feeling accomplished ğŸ’¼'}, {'id': 1837, 'content': 'Late night burgers cravings = satisfied ğŸŒ®'}]}, 'match': 'no', 'confidence': 0.9, 'reasons': ['Strong conflict in current company (ByteDance vs Carousell)', 'Strong conflict in current job title (Engineer vs Scientist)', \"Strong conflict in education level (Bachelor's vs Doctoral Degree)\"], 'score': 0.075}, {'candidate': {'id': 377, 'display_name': 'John Smith', 'city': 'Singapore', 'country': 'Singapore', 'match_type': 'exact'}, 'profile': {'id': 377, 'display_name': 'John Smith', 'original_name': 'John Smith', 'city': 'Singapore', 'country': 'Singapore', 'hometown': 'Hong Kong', 'bio': 'Also lead kitchen I coach available we.  Wish music camera task', 'status': 'Divorced', 'education': \"Bachelor's Degree\", 'current_job': 'Engineer', 'current_company': 'AIA', 'interests': 'Social Media, Podcasting, Online Courses', 'friend_count': 36, 'friends': [98, 235, 1152, 2819, 4741, 2196, 6938, 9249, 1406, 6568, 4906, 3254, 3646, 8515, 75, 1620, 5466, 5594, 7134, 8295, 1897, 108, 7155, 7550, 1400, 2050, 2104, 2296, 3560, 3994, 6066, 6453, 8013, 8788, 9565, 9566], 'posts': [{'id': 2049, 'content': \"Singapore has my heart â¤ï¸ Can't wait to come back\"}, {'id': 2050, 'content': 'Bucket list: Visit Singapore âœ… What an incredible experience!'}, {'id': 2051, 'content': 'Big life update: Starting fresh in Singapore! Wish me luck ğŸŒŸ'}, {'id': 2052, 'content': 'Just got back from Singapore. Already planning my next trip! âœˆï¸'}]}, 'match': 'no', 'confidence': 0.2, 'reasons': ['Strong conflict in current company (ByteDance vs. AIA)', 'Weak alignment on name and location only'], 'score': 0.25}], 'best': {'candidate': {'id': 213, 'display_name': 'John Smith', 'city': 'Singapore', 'country': 'Singapore', 'match_type': 'exact'}, 'profile': {'id': 213, 'display_name': 'John Smith', 'original_name': 'John Smith', 'city': 'Singapore', 'country': 'Singapore', 'hometown': 'Hong Kong', 'bio': 'Evidence ago much.  Amount travel find consumer door near president', 'status': 'Engaged', 'education': \"Bachelor's Degree\", 'current_job': 'Scientist', 'current_company': 'Traveloka', 'interests': 'Machine Learning, Reading, Cooking', 'friend_count': 34, 'friends': [205, 471, 9093, 2344, 247, 1738, 4778, 9391, 283, 368, 5105, 3283, 4022, 6903, 5177, 1755, 5628, 5629, 1075, 1636, 2271, 3616, 4956, 5196, 5592, 5836, 7124, 7201, 8027, 8355, 8577, 8733, 9176, 9770], 'posts': [{'id': 1199, 'content': 'New personal best in Machine Learning! Progress feels amazing ğŸ’ª'}, {'id': 1200, 'content': 'Late night ramen cravings = satisfied ğŸŒ®'}, {'id': 1201, 'content': 'Celebrating small wins today! ğŸŠ'}, {'id': 1202, 'content': 'Family dinner never gets old â¤ï¸ #blessed'}, {'id': 1203, 'content': \"Cousins gathering! Haven't seen everyone in ages! ğŸ‘¨\\u200dğŸ‘©\\u200dğŸ‘§\\u200dğŸ‘¦\"}]}, 'match': 'no', 'confidence': 0.9, 'reasons': ['Strong conflict in current company (ByteDance vs Traveloka)', 'Strong conflict in current job title (Engineer vs Scientist)'], 'score': 0.075}}}\n",
            "[Final] {'score': 0.2, 'verdict': 'no'}\n",
            "CV_1.pdf => 0.2\n",
            "\n",
            "==========================================================================================\n",
            "[DEBUG] CV_2.pdf\n",
            "[Extract] {'name': 'Minh Pham', 'title': 'Design Professional', 'locations': ['Beijing, China', 'Hong Kong'], 'companies': ['BCG', 'Tencent'], 'schools': ['The University of Hong Kong']}\n",
            "[Select-LI] [{'id': 4117, 'name': 'Minh Pham', 'location': 'Kowloon, Hong Kong', 'match_type': 'exact'}, {'id': 2758, 'name': 'Minh Pham', 'location': 'Causeway Bay, Hong Kong', 'match_type': 'exact'}, {'id': 180, 'name': 'Minh Pham', 'location': 'Central, Hong Kong', 'match_type': 'exact'}]\n",
            "[Select-FB] [{'id': 70, 'name': 'Minh Pham', 'location': 'Beijing, China', 'match_type': 'exact'}, {'id': 180, 'name': 'Minh Pham', 'location': 'Central, Hong Kong', 'match_type': 'exact'}, {'id': 702, 'name': 'Minh Pham', 'location': 'Central, Hong Kong', 'match_type': 'exact'}]\n",
            "[Judge-LI] [{'match': 'no', 'confidence': 0.9, 'candidate': {'id': 4117, 'name': 'Minh Pham', 'location': 'Kowloon, Hong Kong', 'match_type': 'exact'}}, {'match': 'no', 'confidence': 0.9, 'candidate': {'id': 2758, 'name': 'Minh Pham', 'location': 'Causeway Bay, Hong Kong', 'match_type': 'exact'}}, {'match': 'no', 'confidence': 0.9, 'candidate': {'id': 180, 'name': 'Minh Pham', 'location': 'Central, Hong Kong', 'match_type': 'exact'}}]\n",
            "[Judge-FB] [{'match': 'no', 'confidence': 0.1, 'candidate': {'id': 70, 'name': 'Minh Pham', 'location': 'Beijing, China', 'match_type': 'exact'}}, {'match': 'no', 'confidence': 0.9, 'candidate': {'id': 180, 'name': 'Minh Pham', 'location': 'Central, Hong Kong', 'match_type': 'exact'}}, {'match': 'no', 'confidence': 0.9, 'candidate': {'id': 702, 'name': 'Minh Pham', 'location': 'Central, Hong Kong', 'match_type': 'exact'}}]\n",
            "[Aggregate] {'li': {'score': 0.075, 'verdict': 'no', 'matches': [{'candidate': {'id': 4117, 'name': 'Minh Pham', 'headline': 'Design Professional', 'industry': 'Design', 'location': 'Kowloon, Hong Kong', 'years_experience': 3, 'match_type': 'exact'}, 'profile': {'id': 4117, 'name': 'Minh Pham', 'headline': 'Design Professional', 'city': 'Kowloon', 'country': 'Hong Kong', 'industry': 'Design', 'status': 'hiring', 'years_experience': 3, 'summary': 'Leave image send. Early book into answer can. General new continue large bank. Their pretty different treatment citizen. Wonder tree thousand nation kitchen particularly cover. Certain weight yeah kid.', 'skills': [{'name': 'Graphic Design', 'proficiency': 1}, {'name': 'Prototyping', 'proficiency': 1}, {'name': 'UI/UX', 'proficiency': 2}], 'experience': [{'company': 'Manulife', 'title': 'Engineer', 'seniority': 'mid', 'start_year': 2017, 'end_year': None, 'is_current': True}, {'company': 'Deloitte', 'title': 'Manager', 'seniority': 'senior', 'start_year': 2020, 'end_year': None, 'is_current': False}, {'company': 'Manulife', 'title': 'Manager', 'seniority': 'junior', 'start_year': 2013, 'end_year': 2015, 'is_current': False}], 'education': [{'school': 'Stanford', 'degree': 'MSc', 'field': 'Design', 'start_year': 2011, 'end_year': 2014}]}, 'match': 'no', 'confidence': 0.9, 'reasons': ['Company history is completely different and non-overlapping', 'Education institutions are completely different', 'Current employment status and titles conflict'], 'score': 0.075}, {'candidate': {'id': 2758, 'name': 'Minh Pham', 'headline': 'Design Professional', 'industry': 'Design', 'location': 'Causeway Bay, Hong Kong', 'years_experience': 1, 'match_type': 'exact'}, 'profile': {'id': 2758, 'name': 'Minh Pham', 'headline': 'Design Professional', 'city': 'Causeway Bay', 'country': 'Hong Kong', 'industry': 'Design', 'status': 'open_to_work', 'years_experience': 1, 'summary': 'Rather population still almost. Almost court certain central. Unit yard somebody life.', 'skills': [{'name': 'Graphic Design', 'proficiency': 1}, {'name': 'Prototyping', 'proficiency': 3}, {'name': 'UI/UX', 'proficiency': 3}], 'experience': [{'company': 'Carousell', 'title': 'Scientist', 'seniority': 'mid', 'start_year': 2013, 'end_year': None, 'is_current': False}, {'company': 'Bank of East Asia', 'title': 'Engineer', 'seniority': 'mid', 'start_year': 2017, 'end_year': None, 'is_current': True}, {'company': 'Traveloka', 'title': 'Manager', 'seniority': 'junior', 'start_year': 2017, 'end_year': 2020, 'is_current': False}], 'education': [{'school': 'McGill University', 'degree': 'PhD', 'field': 'Design', 'start_year': 2002, 'end_year': 2006}]}, 'match': 'no', 'confidence': 0.9, 'reasons': ['Major conflict in company experience (BCG/Tencent vs Carousell/Bank of East Asia/Traveloka)', 'Major conflict in education (University of Hong Kong vs McGill University)', 'Strong alignment in skills and title/industry is insufficient to overcome core identity conflicts'], 'score': 0.075}, {'candidate': {'id': 180, 'name': 'Minh Pham', 'headline': 'Consulting Professional', 'industry': 'Consulting', 'location': 'Central, Hong Kong', 'years_experience': 6, 'match_type': 'exact'}, 'profile': {'id': 180, 'name': 'Minh Pham', 'headline': 'Consulting Professional', 'city': 'Central', 'country': 'Hong Kong', 'industry': 'Consulting', 'status': 'student', 'years_experience': 6, 'summary': 'Join so reality bit design save floor mean. Provide tree see coach. Forget or create here gun. Describe believe career mouth type building. Range near yeah city action individual.', 'skills': [{'name': 'PowerPoint', 'proficiency': 4}, {'name': 'Data Analysis', 'proficiency': 1}, {'name': 'Problem Solving', 'proficiency': 3}], 'experience': [{'company': 'Grab', 'title': 'Engineer', 'seniority': 'junior', 'start_year': 2015, 'end_year': None, 'is_current': False}], 'education': [{'school': 'Oxford', 'degree': 'MBA', 'field': 'Consulting', 'start_year': 2005, 'end_year': 2010}]}, 'match': 'no', 'confidence': 0.9, 'reasons': ['Major conflict in companies/experience: resume shows BCG/Tencent, profile shows Grab', 'Major conflict in education: resume shows University of Hong Kong, profile shows Oxford', 'Major conflict in skills: resume shows design skills, profile shows consulting/analysis skills', 'Title/industry mismatch: resume shows Design Professional, profile shows Consulting Professional'], 'score': 0.075}], 'best': {'candidate': {'id': 4117, 'name': 'Minh Pham', 'headline': 'Design Professional', 'industry': 'Design', 'location': 'Kowloon, Hong Kong', 'years_experience': 3, 'match_type': 'exact'}, 'profile': {'id': 4117, 'name': 'Minh Pham', 'headline': 'Design Professional', 'city': 'Kowloon', 'country': 'Hong Kong', 'industry': 'Design', 'status': 'hiring', 'years_experience': 3, 'summary': 'Leave image send. Early book into answer can. General new continue large bank. Their pretty different treatment citizen. Wonder tree thousand nation kitchen particularly cover. Certain weight yeah kid.', 'skills': [{'name': 'Graphic Design', 'proficiency': 1}, {'name': 'Prototyping', 'proficiency': 1}, {'name': 'UI/UX', 'proficiency': 2}], 'experience': [{'company': 'Manulife', 'title': 'Engineer', 'seniority': 'mid', 'start_year': 2017, 'end_year': None, 'is_current': True}, {'company': 'Deloitte', 'title': 'Manager', 'seniority': 'senior', 'start_year': 2020, 'end_year': None, 'is_current': False}, {'company': 'Manulife', 'title': 'Manager', 'seniority': 'junior', 'start_year': 2013, 'end_year': 2015, 'is_current': False}], 'education': [{'school': 'Stanford', 'degree': 'MSc', 'field': 'Design', 'start_year': 2011, 'end_year': 2014}]}, 'match': 'no', 'confidence': 0.9, 'reasons': ['Company history is completely different and non-overlapping', 'Education institutions are completely different', 'Current employment status and titles conflict'], 'score': 0.075}}, 'fb': {'score': 0.075, 'verdict': 'no', 'matches': [{'candidate': {'id': 70, 'display_name': 'Minh Pham', 'city': 'Beijing', 'country': 'China', 'match_type': 'exact'}, 'profile': {'id': 70, 'display_name': 'Minh Pham', 'original_name': 'Minh Pham', 'city': 'Beijing', 'country': 'China', 'hometown': 'Hong Kong', 'bio': 'Discover last dream fall significant build soldier.  Must field time old which minute teach', 'status': 'In a civil union', 'education': \"Master's Degree\", 'current_job': 'Engineer', 'current_company': 'Manulife', 'interests': 'Machine Learning, Research, Music Production', 'friend_count': 48, 'friends': [4865, 5515, 5901, 6679, 4762, 7967, 2082, 4273, 5430, 5309, 4160, 9030, 5318, 6219, 3661, 3406, 7635, 1108, 84, 7002, 3943, 5611, 242, 4345, 1916, 115, 533, 718, 844, 971, 973, 1049, 1128, 1968, 2462, 2890, 3082, 5295, 5504, 5737, 5827, 5967, 6560, 6699, 8461, 9300, 9795, 9817], 'posts': [{'id': 401, 'content': 'Another year older, another year wiser ğŸ¥‚'}, {'id': 402, 'content': 'Hit a new gym milestone today! Consistency pays off ğŸ’ª'}, {'id': 403, 'content': '2024 goals: Less stress, more Machine Learning'}, {'id': 404, 'content': 'Networking event in Beijing last night. Made great connections!'}, {'id': 405, 'content': 'Living my best life in Beijing! ğŸŒŸ'}]}, 'match': 'no', 'confidence': 0.1, 'reasons': ['Strong conflict in current company and job title (BCG Manager vs. Manulife Engineer)', 'Strong conflict in industry/field (Design vs. Engineering)', \"Education details conflict (BSc Design vs. Master's Degree unspecified)\"], 'score': 0.275}, {'candidate': {'id': 180, 'display_name': 'Minh Pham', 'city': 'Central', 'country': 'Hong Kong', 'match_type': 'exact'}, 'profile': {'id': 180, 'display_name': 'Minh Pham', 'original_name': 'Minh Pham', 'city': 'Central', 'country': 'Hong Kong', 'hometown': 'London', 'bio': 'Join so reality bit design save floor mean.  Provide tree see coach', 'status': None, 'education': \"Master's Degree\", 'current_job': 'Engineer', 'current_company': 'Grab', 'interests': 'Public Speaking, Networking, Podcasts, Documentaries', 'friend_count': 45, 'friends': [6017, 3974, 9615, 7952, 9497, 1698, 9252, 6575, 3391, 3012, 4808, 8008, 3661, 5069, 6992, 8401, 7122, 8044, 6521, 9595, 2813, 240, 610, 1365, 2010, 2422, 2835, 2901, 2962, 3000, 3669, 4258, 5150, 5439, 5729, 6222, 6385, 6472, 6550, 7305, 8137, 8214, 8905, 9824, 9978], 'posts': [{'id': 1000, 'content': \"Cousins gathering! Haven't seen everyone in ages! ğŸ‘¨\\u200dğŸ‘©\\u200dğŸ‘§\\u200dğŸ‘¦\"}, {'id': 1001, 'content': 'Feeling grateful and blessed today ğŸ™'}, {'id': 1002, 'content': \"Travel goal for 2024: Finally visit Central! Who's been?\"}, {'id': 1003, 'content': 'Restaurant recommendations for Central? Drop them below! ğŸ‘‡'}, {'id': 1004, 'content': 'Sometimes you just need to unplug and recharge ğŸ”‹'}, {'id': 1005, 'content': 'Completed my certification in Networking! Never stop learning ğŸ“š'}, {'id': 1006, 'content': 'Throwback to my college days in London. Time flies! ğŸ“¸'}]}, 'match': 'no', 'confidence': 0.9, 'reasons': ['Major conflict in current company (BCG vs Grab)', 'Major conflict in current job title (Design Professional/Manager vs Engineer)', 'No overlap in skills or education details'], 'score': 0.075}, {'candidate': {'id': 702, 'display_name': 'Minh Pham', 'city': 'Central', 'country': 'Hong Kong', 'match_type': 'exact'}, 'profile': {'id': 702, 'display_name': 'Minh Pham', 'original_name': 'Minh Pham', 'city': 'Central', 'country': 'Hong Kong', 'hometown': 'Hong Kong', 'bio': 'AI professional | Tech Conferences & Reading | ğŸ“ Central', 'status': 'In a relationship', 'education': \"Master's Degree\", 'current_job': 'Engineer', 'current_company': 'Gojek', 'interests': 'Tech Conferences, Reading, Podcasts, Language Learning', 'friend_count': 53, 'friends': [9221, 5127, 3849, 920, 8219, 412, 6690, 5796, 423, 1959, 813, 3249, 8380, 9532, 1854, 7109, 5830, 7372, 5964, 3663, 2010, 8028, 9440, 1632, 610, 1639, 5352, 494, 5884, 967, 1291, 2270, 2642, 2962, 3259, 3980, 4241, 5093, 5237, 5599, 5653, 6035, 6510, 6806, 7121, 7658, 7989, 8065, 8310, 8362, 8512, 8905, 9984], 'posts': [{'id': 3809, 'content': 'Family dinner never gets old â¤ï¸ #blessed'}, {'id': 3810, 'content': 'Just finished binge-watching that new series. Mind blown! ğŸ¬'}, {'id': 3811, 'content': \"Central has my heart â¤ï¸ Can't wait to come back\"}]}, 'match': 'no', 'confidence': 0.9, 'reasons': ['Major career field mismatch: resume is Design, profile is Engineering/AI', 'Current company conflict: resume shows BCG/Tencent, profile shows Gojek', \"Education level conflict: resume shows BSc, profile shows Master's\"], 'score': 0.075}], 'best': {'candidate': {'id': 180, 'display_name': 'Minh Pham', 'city': 'Central', 'country': 'Hong Kong', 'match_type': 'exact'}, 'profile': {'id': 180, 'display_name': 'Minh Pham', 'original_name': 'Minh Pham', 'city': 'Central', 'country': 'Hong Kong', 'hometown': 'London', 'bio': 'Join so reality bit design save floor mean.  Provide tree see coach', 'status': None, 'education': \"Master's Degree\", 'current_job': 'Engineer', 'current_company': 'Grab', 'interests': 'Public Speaking, Networking, Podcasts, Documentaries', 'friend_count': 45, 'friends': [6017, 3974, 9615, 7952, 9497, 1698, 9252, 6575, 3391, 3012, 4808, 8008, 3661, 5069, 6992, 8401, 7122, 8044, 6521, 9595, 2813, 240, 610, 1365, 2010, 2422, 2835, 2901, 2962, 3000, 3669, 4258, 5150, 5439, 5729, 6222, 6385, 6472, 6550, 7305, 8137, 8214, 8905, 9824, 9978], 'posts': [{'id': 1000, 'content': \"Cousins gathering! Haven't seen everyone in ages! ğŸ‘¨\\u200dğŸ‘©\\u200dğŸ‘§\\u200dğŸ‘¦\"}, {'id': 1001, 'content': 'Feeling grateful and blessed today ğŸ™'}, {'id': 1002, 'content': \"Travel goal for 2024: Finally visit Central! Who's been?\"}, {'id': 1003, 'content': 'Restaurant recommendations for Central? Drop them below! ğŸ‘‡'}, {'id': 1004, 'content': 'Sometimes you just need to unplug and recharge ğŸ”‹'}, {'id': 1005, 'content': 'Completed my certification in Networking! Never stop learning ğŸ“š'}, {'id': 1006, 'content': 'Throwback to my college days in London. Time flies! ğŸ“¸'}]}, 'match': 'no', 'confidence': 0.9, 'reasons': ['Major conflict in current company (BCG vs Grab)', 'Major conflict in current job title (Design Professional/Manager vs Engineer)', 'No overlap in skills or education details'], 'score': 0.075}}}\n",
            "[Final] {'score': 0.2, 'verdict': 'no'}\n",
            "CV_2.pdf => 0.2\n",
            "\n",
            "==========================================================================================\n",
            "[DEBUG] CV_3.pdf\n",
            "[Extract] {'name': 'Wei Zhang', 'title': 'Engineer', 'locations': ['Munich, Germany', 'Sydney (Hometown)'], 'companies': ['PwC'], 'schools': ['University of Tokyo']}\n",
            "[Select-LI] [{'id': 97, 'name': 'Wei Zhang', 'location': 'Munich, Germany', 'match_type': 'exact'}, {'id': 24, 'name': 'Wei Zhang', 'location': 'Sydney, Australia', 'match_type': 'exact'}, {'id': 37, 'name': 'Wei Zhang', 'location': 'Hyderabad, India', 'match_type': 'exact'}]\n",
            "[Select-FB] [{'id': 97, 'name': 'Wei Zhang', 'location': 'Munich, Germany', 'match_type': 'exact'}, {'id': 383, 'name': 'Wei Zhang', 'location': 'Berlin, Germany', 'match_type': 'exact'}, {'id': 76, 'name': 'Wei Zhang', 'location': 'San Francisco, USA', 'match_type': 'exact'}]\n",
            "[Judge-LI] [{'match': 'yes', 'confidence': 0.9, 'candidate': {'id': 97, 'name': 'Wei Zhang', 'location': 'Munich, Germany', 'match_type': 'exact'}}, {'match': 'no', 'confidence': 0.9, 'candidate': {'id': 24, 'name': 'Wei Zhang', 'location': 'Sydney, Australia', 'match_type': 'exact'}}, {'match': 'no', 'confidence': 0.9, 'candidate': {'id': 37, 'name': 'Wei Zhang', 'location': 'Hyderabad, India', 'match_type': 'exact'}}]\n",
            "[Judge-FB] [{'match': 'yes', 'confidence': 0.9, 'candidate': {'id': 97, 'name': 'Wei Zhang', 'location': 'Munich, Germany', 'match_type': 'exact'}}, {'match': 'no', 'confidence': 0.2, 'candidate': {'id': 383, 'name': 'Wei Zhang', 'location': 'Berlin, Germany', 'match_type': 'exact'}}, {'match': 'no', 'confidence': 0.2, 'candidate': {'id': 76, 'name': 'Wei Zhang', 'location': 'San Francisco, USA', 'match_type': 'exact'}}]\n",
            "[Aggregate] {'li': {'score': 0.9650000000000001, 'verdict': 'yes', 'matches': [{'candidate': {'id': 97, 'name': 'Wei Zhang', 'headline': 'Consulting Professional', 'industry': 'Consulting', 'location': 'Munich, Germany', 'years_experience': 15, 'match_type': 'exact'}, 'profile': {'id': 97, 'name': 'Wei Zhang', 'headline': 'Consulting Professional', 'city': 'Munich', 'country': 'Germany', 'industry': 'Consulting', 'status': 'hiring', 'years_experience': 15, 'summary': 'Debate but be believe situation season. They with carry tough wide economy wind. Forward police professional scene whatever ever foreign able.', 'skills': [{'name': 'Data Analysis', 'proficiency': 5}, {'name': 'PowerPoint', 'proficiency': 5}, {'name': 'Problem Solving', 'proficiency': 1}, {'name': 'Strategy', 'proficiency': 5}], 'experience': [{'company': 'PwC', 'title': 'Engineer', 'seniority': 'junior', 'start_year': 2013, 'end_year': None, 'is_current': False}], 'education': [{'school': 'University of Tokyo', 'degree': 'BSc', 'field': 'Consulting', 'start_year': 2011, 'end_year': 2015}]}, 'match': 'yes', 'confidence': 0.9, 'reasons': ['Strong alignment on company (PwC) and title (Engineer) with matching start year (2013)', 'Strong alignment on school (University of Tokyo) and degree field (Consulting)', 'Location match (Munich, Germany) and industry alignment (Consulting)', 'Multiple overlapping skills (Data Analysis, PowerPoint, Problem Solving, Strategy)'], 'score': 0.9650000000000001}, {'candidate': {'id': 24, 'name': 'Wei Zhang', 'headline': 'Legal Professional', 'industry': 'Legal', 'location': 'Sydney, Australia', 'years_experience': 15, 'match_type': 'exact'}, 'profile': {'id': 24, 'name': 'Wei Zhang', 'headline': 'Legal Professional', 'city': 'Sydney', 'country': 'Australia', 'industry': 'Legal', 'status': 'student', 'years_experience': 15, 'summary': 'Specific charge company collection. Two mother rate per not create. You pay whether speech through. Section keep all fire provide spring consumer. Drop method arrive property five prove describe. Her question book allow.', 'skills': [{'name': 'Litigation', 'proficiency': 3}, {'name': 'Compliance', 'proficiency': 4}, {'name': 'Contract Review', 'proficiency': 3}], 'experience': [{'company': 'Shopee', 'title': 'Engineer', 'seniority': 'senior', 'start_year': 2011, 'end_year': None, 'is_current': False}, {'company': 'Traveloka', 'title': 'Manager', 'seniority': 'junior', 'start_year': 2006, 'end_year': 2012, 'is_current': True}, {'company': 'TechWorks', 'title': 'Manager', 'seniority': 'junior', 'start_year': 2014, 'end_year': None, 'is_current': False}], 'education': [{'school': 'KAIST', 'degree': 'MBA', 'field': 'Legal', 'start_year': 2007, 'end_year': 2010}]}, 'match': 'no', 'confidence': 0.9, 'reasons': ['Major conflict in companies (PwC vs. Shopee/Traveloka/TechWorks)', 'Major conflict in education (University of Tokyo vs. KAIST)', 'Major conflict in industry/skills (Analytical/Business vs. Legal/Litigation)'], 'score': 0.075}, {'candidate': {'id': 37, 'name': 'Wei Zhang', 'headline': 'Education Professional', 'industry': 'Education', 'location': 'Hyderabad, India', 'years_experience': 1, 'match_type': 'exact'}, 'profile': {'id': 37, 'name': 'Wei Zhang', 'headline': 'Education Professional', 'city': 'Hyderabad', 'country': 'India', 'industry': 'Education', 'status': 'employed', 'years_experience': 1, 'summary': 'Scientist computer six born usually. Trip budget prepare attorney age stay. Policy reach run cup social whatever that.', 'skills': [{'name': 'Curriculum Design', 'proficiency': 4}, {'name': 'Statistics', 'proficiency': 3}, {'name': 'Research', 'proficiency': 3}, {'name': 'Teaching', 'proficiency': 4}], 'experience': [{'company': 'AIA', 'title': 'Engineer', 'seniority': 'junior', 'start_year': 2019, 'end_year': None, 'is_current': False}], 'education': [{'school': 'NTU', 'degree': 'MSc', 'field': 'Education', 'start_year': 2012, 'end_year': 2015}]}, 'match': 'no', 'confidence': 0.9, 'reasons': ['Major conflict in companies (PwC vs AIA)', 'Major conflict in education (University of Tokyo vs NTU)', 'Major conflict in industry (Consulting/Engineering vs Education)', 'Major conflict in skills (Analytical/Business vs Curriculum Design/Teaching)'], 'score': 0.075}], 'best': {'candidate': {'id': 97, 'name': 'Wei Zhang', 'headline': 'Consulting Professional', 'industry': 'Consulting', 'location': 'Munich, Germany', 'years_experience': 15, 'match_type': 'exact'}, 'profile': {'id': 97, 'name': 'Wei Zhang', 'headline': 'Consulting Professional', 'city': 'Munich', 'country': 'Germany', 'industry': 'Consulting', 'status': 'hiring', 'years_experience': 15, 'summary': 'Debate but be believe situation season. They with carry tough wide economy wind. Forward police professional scene whatever ever foreign able.', 'skills': [{'name': 'Data Analysis', 'proficiency': 5}, {'name': 'PowerPoint', 'proficiency': 5}, {'name': 'Problem Solving', 'proficiency': 1}, {'name': 'Strategy', 'proficiency': 5}], 'experience': [{'company': 'PwC', 'title': 'Engineer', 'seniority': 'junior', 'start_year': 2013, 'end_year': None, 'is_current': False}], 'education': [{'school': 'University of Tokyo', 'degree': 'BSc', 'field': 'Consulting', 'start_year': 2011, 'end_year': 2015}]}, 'match': 'yes', 'confidence': 0.9, 'reasons': ['Strong alignment on company (PwC) and title (Engineer) with matching start year (2013)', 'Strong alignment on school (University of Tokyo) and degree field (Consulting)', 'Location match (Munich, Germany) and industry alignment (Consulting)', 'Multiple overlapping skills (Data Analysis, PowerPoint, Problem Solving, Strategy)'], 'score': 0.9650000000000001}}, 'fb': {'score': 0.9650000000000001, 'verdict': 'yes', 'matches': [{'candidate': {'id': 97, 'display_name': 'Wei Zhang', 'city': 'Munich', 'country': 'Germany', 'match_type': 'exact'}, 'profile': {'id': 97, 'display_name': 'Wei Zhang', 'original_name': 'Wei Zhang', 'city': 'Munich', 'country': 'Germany', 'hometown': 'Munich', 'bio': 'Living in Munich | Public Speaking enthusiast | Consulting', 'status': 'Divorced', 'education': \"Bachelor's Degree\", 'current_job': 'Engineer', 'current_company': 'PwC', 'interests': 'Public Speaking, Networking, Music Production, Concerts', 'friend_count': 49, 'friends': [4868, 4359, 8976, 2193, 9875, 28, 3234, 1828, 3365, 678, 6954, 2864, 5424, 8625, 1717, 7997, 9022, 8384, 9026, 322, 455, 6873, 3301, 7272, 8943, 9970, 5236, 4340, 117, 3705, 600, 625, 1125, 1656, 2608, 2931, 2990, 5275, 5523, 6004, 6563, 6832, 7372, 7742, 7881, 8666, 8791, 9361, 9591], 'posts': [{'id': 551, 'content': 'Family dinner never gets old â¤ï¸ #blessed'}, {'id': 552, 'content': 'Friday mood! Weekend plans? ğŸ‰'}, {'id': 553, 'content': 'That Monday feeling... need coffee â˜•'}]}, 'match': 'yes', 'confidence': 0.9, 'reasons': ['Strong alignment on current company (PwC) and job title (Engineer)', 'Strong alignment on current location (Munich, Germany)', \"Education level (Bachelor's Degree) and industry (Consulting) are consistent with resume details\"], 'score': 0.9650000000000001}, {'candidate': {'id': 383, 'display_name': 'Wei Zhang', 'city': 'Berlin', 'country': 'Germany', 'match_type': 'exact'}, 'profile': {'id': 383, 'display_name': 'Wei Zhang', 'original_name': 'Wei Zhang', 'city': 'Berlin', 'country': 'Germany', 'hometown': 'Hong Kong', 'bio': 'Tree exist as public create join what.  Skill per modern star ok', 'status': 'Separated', 'education': \"Master's Degree\", 'current_job': 'Analyst', 'current_company': 'Bright Solutions', 'interests': 'Digital Art, Sketching, Online Courses', 'friend_count': 43, 'friends': [5761, 389, 4232, 9485, 5144, 6298, 9375, 1952, 3232, 2216, 8492, 5040, 832, 6849, 7122, 4310, 4183, 4188, 6380, 1114, 1225, 1721, 2185, 2968, 3686, 4264, 4450, 4587, 5575, 5728, 5963, 6156, 6211, 6500, 7429, 7754, 8141, 8155, 8216, 8309, 8892, 9621, 9737], 'posts': [{'id': 2078, 'content': 'Found the best Indian restaurant in Berlin! Highly recommend ğŸœ'}, {'id': 2079, 'content': 'Tried cooking sushi for the first time. Not bad! ğŸ‘¨\\u200dğŸ³'}, {'id': 2080, 'content': 'Bucket list: Visit Berlin âœ… What an incredible experience!'}]}, 'match': 'no', 'confidence': 0.2, 'reasons': ['Strong conflict in current company (PwC vs Bright Solutions)', 'Strong conflict in current job title (Engineer vs Analyst)', \"Education details conflict (BSc in Consulting vs Master's Degree with unspecified field)\"], 'score': 0.25}, {'candidate': {'id': 76, 'display_name': 'Wei Zhang', 'city': 'San Francisco', 'country': 'USA', 'match_type': 'exact'}, 'profile': {'id': 76, 'display_name': 'Wei Zhang', 'original_name': 'Wei Zhang', 'city': 'San Francisco', 'country': 'USA', 'hometown': 'San Francisco', 'bio': 'Entire current best bed end simple her.  Live high relate could someone if', 'status': 'Single', 'education': \"Master's Degree\", 'current_job': 'Analyst', 'current_company': 'Meta', 'interests': 'Photography, UI/UX, Language Learning, Documentaries', 'friend_count': 38, 'friends': [4161, 4867, 3845, 8293, 1803, 1581, 9453, 9041, 7826, 2769, 7282, 5459, 5206, 2938, 8636, 3263, 1655, 1974, 2488, 2574, 3444, 3965, 3996, 4281, 4315, 4409, 4990, 5321, 5476, 5756, 5878, 8140, 8736, 8776, 8902, 9203, 9529, 9659], 'posts': [{'id': 430, 'content': 'New year, new focus on UI/UX!'}, {'id': 431, 'content': 'Finally getting back into Language Learning after ages!'}, {'id': 432, 'content': 'Found the best Japanese restaurant in San Francisco! Highly recommend ğŸœ'}, {'id': 433, 'content': 'Just another day in paradise ğŸŒ´'}, {'id': 434, 'content': 'Just got back from San Francisco. Already planning my next trip! âœˆï¸'}, {'id': 435, 'content': 'Celebrating small wins today! ğŸŠ'}, {'id': 436, 'content': 'Photo dump from this weekend! ğŸ“¸'}, {'id': 437, 'content': 'Excited to start my new role as Analyst at Meta! ğŸ‰'}]}, 'match': 'no', 'confidence': 0.2, 'reasons': ['Strong conflict in current company (PwC vs. Meta)', 'Strong conflict in current job title (Engineer vs. Analyst)', 'No overlapping strong signals like school or skills'], 'score': 0.25}], 'best': {'candidate': {'id': 97, 'display_name': 'Wei Zhang', 'city': 'Munich', 'country': 'Germany', 'match_type': 'exact'}, 'profile': {'id': 97, 'display_name': 'Wei Zhang', 'original_name': 'Wei Zhang', 'city': 'Munich', 'country': 'Germany', 'hometown': 'Munich', 'bio': 'Living in Munich | Public Speaking enthusiast | Consulting', 'status': 'Divorced', 'education': \"Bachelor's Degree\", 'current_job': 'Engineer', 'current_company': 'PwC', 'interests': 'Public Speaking, Networking, Music Production, Concerts', 'friend_count': 49, 'friends': [4868, 4359, 8976, 2193, 9875, 28, 3234, 1828, 3365, 678, 6954, 2864, 5424, 8625, 1717, 7997, 9022, 8384, 9026, 322, 455, 6873, 3301, 7272, 8943, 9970, 5236, 4340, 117, 3705, 600, 625, 1125, 1656, 2608, 2931, 2990, 5275, 5523, 6004, 6563, 6832, 7372, 7742, 7881, 8666, 8791, 9361, 9591], 'posts': [{'id': 551, 'content': 'Family dinner never gets old â¤ï¸ #blessed'}, {'id': 552, 'content': 'Friday mood! Weekend plans? ğŸ‰'}, {'id': 553, 'content': 'That Monday feeling... need coffee â˜•'}]}, 'match': 'yes', 'confidence': 0.9, 'reasons': ['Strong alignment on current company (PwC) and job title (Engineer)', 'Strong alignment on current location (Munich, Germany)', \"Education level (Bachelor's Degree) and industry (Consulting) are consistent with resume details\"], 'score': 0.9650000000000001}}}\n",
            "[Final] {'score': 0.9850000000000001, 'verdict': 'yes'}\n",
            "CV_3.pdf => 0.9850000000000001\n",
            "\n",
            "==========================================================================================\n",
            "[DEBUG] CV_4.pdf\n",
            "[Extract] {'name': 'Rahul Sharma', 'title': 'Legal Professional', 'locations': ['Singapore', 'Philippines'], 'companies': ['Microsoft', 'StartupXYZ'], 'schools': ['Tsinghua University']}\n",
            "[Select-LI] [{'id': 2919, 'name': 'Rahul Sharma', 'location': 'Singapore, Singapore', 'match_type': 'exact'}, {'id': 91, 'name': 'Rahul Sharma', 'location': 'Cebu, Philippines', 'match_type': 'exact'}, {'id': 3008, 'name': 'Rahul Sharma', 'location': 'Cebu, Philippines', 'match_type': 'exact'}]\n",
            "[Select-FB] [{'id': 765, 'name': 'Rahul Sharma', 'location': 'Singapore, Singapore', 'match_type': 'exact'}, {'id': 823, 'name': 'Rahul Sharma', 'location': 'Singapore, Singapore', 'match_type': 'exact'}, {'id': 909, 'name': 'Rahul Sharma', 'location': 'Manila, Philippines', 'match_type': 'exact'}]\n",
            "[Judge-LI] [{'match': 'no', 'confidence': 0.9, 'candidate': {'id': 2919, 'name': 'Rahul Sharma', 'location': 'Singapore, Singapore', 'match_type': 'exact'}}, {'match': 'no', 'confidence': 0.8, 'candidate': {'id': 91, 'name': 'Rahul Sharma', 'location': 'Cebu, Philippines', 'match_type': 'exact'}}, {'match': 'no', 'confidence': 0.9, 'candidate': {'id': 3008, 'name': 'Rahul Sharma', 'location': 'Cebu, Philippines', 'match_type': 'exact'}}]\n",
            "[Judge-FB] [{'match': 'no', 'confidence': 0.8, 'candidate': {'id': 765, 'name': 'Rahul Sharma', 'location': 'Singapore, Singapore', 'match_type': 'exact'}}, {'match': 'no', 'confidence': 0.9, 'candidate': {'id': 823, 'name': 'Rahul Sharma', 'location': 'Singapore, Singapore', 'match_type': 'exact'}}, {'match': 'no', 'confidence': 0.9, 'candidate': {'id': 909, 'name': 'Rahul Sharma', 'location': 'Manila, Philippines', 'match_type': 'exact'}}]\n",
            "[Aggregate] {'li': {'score': 0.075, 'verdict': 'no', 'matches': [{'candidate': {'id': 2919, 'name': 'Rahul Sharma', 'headline': 'Legal Professional', 'industry': 'Legal', 'location': 'Singapore, Singapore', 'years_experience': 11, 'match_type': 'exact'}, 'profile': {'id': 2919, 'name': 'Rahul Sharma', 'headline': 'Legal Professional', 'city': 'Singapore', 'country': 'Singapore', 'industry': 'Legal', 'status': 'student', 'years_experience': 11, 'summary': 'Population bed collection season rest go. Girl health measure pass go. Exactly still bit improve. Ground either across management situation simply book.', 'skills': [{'name': 'Compliance', 'proficiency': 5}, {'name': 'Litigation', 'proficiency': 1}, {'name': 'Contract Review', 'proficiency': 3}], 'experience': [{'company': 'Tencent', 'title': 'Analyst', 'seniority': 'senior', 'start_year': 2019, 'end_year': 2023, 'is_current': True}], 'education': [{'school': 'Stanford', 'degree': 'MSc', 'field': 'Legal', 'start_year': 2006, 'end_year': 2010}]}, 'match': 'no', 'confidence': 0.9, 'reasons': ['Major conflict in company experience (Microsoft vs Tencent)', 'Major conflict in education (Tsinghua PhD vs Stanford MSc)', 'Skills and location are only weak/partial matches'], 'score': 0.075}, {'candidate': {'id': 91, 'name': 'Rahul Sharma', 'headline': 'Legal Professional', 'industry': 'Legal', 'location': 'Cebu, Philippines', 'years_experience': 2, 'match_type': 'exact'}, 'profile': {'id': 91, 'name': 'Rahul Sharma', 'headline': 'Legal Professional', 'city': 'Cebu', 'country': 'Philippines', 'industry': 'Legal', 'status': 'student', 'years_experience': 2, 'summary': 'Stock scientist unit. Fact explain particular including represent any night meeting. Through water both past road. Western animal focus treatment federal top number. Lot development safe side on senior.', 'skills': [{'name': 'Compliance', 'proficiency': 5}, {'name': 'Litigation', 'proficiency': 5}, {'name': 'Contract Review', 'proficiency': 2}], 'experience': [{'company': 'Microsoft', 'title': 'Engineer', 'seniority': 'junior', 'start_year': 2020, 'end_year': 2025, 'is_current': True}], 'education': [{'school': 'Tsinghua University', 'degree': 'PhD', 'field': 'Legal', 'start_year': 2014, 'end_year': 2019}]}, 'match': 'no', 'confidence': 0.8, 'reasons': ['Strong conflict in company role and timeline', 'Significant mismatch in skills and education timeline'], 'score': 0.09999999999999999}, {'candidate': {'id': 3008, 'name': 'Rahul Sharma', 'headline': 'Legal Professional', 'industry': 'Legal', 'location': 'Cebu, Philippines', 'years_experience': 4, 'match_type': 'exact'}, 'profile': {'id': 3008, 'name': 'Rahul Sharma', 'headline': 'Legal Professional', 'city': 'Cebu', 'country': 'Philippines', 'industry': 'Legal', 'status': 'student', 'years_experience': 4, 'summary': 'Way off hot drive sense building partner seek. Money baby increase space set. Voice old scientist interview ground point range. Along whether send without learn. Commercial total public stop range crime.', 'skills': [{'name': 'Contract Review', 'proficiency': 2}, {'name': 'Compliance', 'proficiency': 3}, {'name': 'Litigation', 'proficiency': 3}], 'experience': [{'company': 'Alibaba', 'title': 'Manager', 'seniority': 'junior', 'start_year': 2014, 'end_year': None, 'is_current': True}], 'education': [{'school': 'McGill University', 'degree': 'MSc', 'field': 'Legal', 'start_year': 2009, 'end_year': 2014}]}, 'match': 'no', 'confidence': 0.9, 'reasons': ['Major company conflict (Microsoft vs. Alibaba)', 'Major school conflict (Tsinghua vs. McGill)', 'Experience title mismatch (Senior Engineer/Consultant vs. Manager)'], 'score': 0.075}], 'best': {'candidate': {'id': 2919, 'name': 'Rahul Sharma', 'headline': 'Legal Professional', 'industry': 'Legal', 'location': 'Singapore, Singapore', 'years_experience': 11, 'match_type': 'exact'}, 'profile': {'id': 2919, 'name': 'Rahul Sharma', 'headline': 'Legal Professional', 'city': 'Singapore', 'country': 'Singapore', 'industry': 'Legal', 'status': 'student', 'years_experience': 11, 'summary': 'Population bed collection season rest go. Girl health measure pass go. Exactly still bit improve. Ground either across management situation simply book.', 'skills': [{'name': 'Compliance', 'proficiency': 5}, {'name': 'Litigation', 'proficiency': 1}, {'name': 'Contract Review', 'proficiency': 3}], 'experience': [{'company': 'Tencent', 'title': 'Analyst', 'seniority': 'senior', 'start_year': 2019, 'end_year': 2023, 'is_current': True}], 'education': [{'school': 'Stanford', 'degree': 'MSc', 'field': 'Legal', 'start_year': 2006, 'end_year': 2010}]}, 'match': 'no', 'confidence': 0.9, 'reasons': ['Major conflict in company experience (Microsoft vs Tencent)', 'Major conflict in education (Tsinghua PhD vs Stanford MSc)', 'Skills and location are only weak/partial matches'], 'score': 0.075}}, 'fb': {'score': 0.075, 'verdict': 'no', 'matches': [{'candidate': {'id': 765, 'display_name': 'Rahul Sharma', 'city': 'Singapore', 'country': 'Singapore', 'match_type': 'exact'}, 'profile': {'id': 765, 'display_name': 'Rahul Sharma', 'original_name': 'Rahul Sharma', 'city': 'Singapore', 'country': 'Singapore', 'hometown': 'Singapore', 'bio': 'Inside still often other walk instead manage.  Management focus sort face degree most hold', 'status': 'In a civil union', 'education': \"Master's Degree\", 'current_job': 'Manager', 'current_company': 'Shopee', 'interests': 'Public Speaking, Networking, Photography', 'friend_count': 47, 'friends': [83, 162, 211, 283, 3715, 4875, 654, 9486, 7061, 5529, 6813, 4010, 3637, 8127, 3007, 8132, 8005, 8788, 7252, 2022, 486, 5094, 2278, 3950, 8050, 2930, 4601, 8828, 2427, 2897, 3084, 3457, 3972, 4020, 4791, 4792, 4929, 5058, 5221, 6352, 6658, 7063, 7155, 7226, 7548, 8726, 9089], 'posts': [{'id': 4151, 'content': 'Random acts of kindness make the world better â¤ï¸'}, {'id': 4152, 'content': \"What's everyone up to this weekend in Singapore?\"}, {'id': 4153, 'content': 'Throwback to my college days in Singapore. Time flies! ğŸ“¸'}, {'id': 4154, 'content': \"Travel goal for 2024: Finally visit Singapore! Who's been?\"}, {'id': 4155, 'content': 'Completed my certification in Photography! Never stop learning ğŸ“š'}, {'id': 4156, 'content': 'Grateful for friends who feel like family ğŸ™'}, {'id': 4157, 'content': 'Just finished binge-watching that new series. Mind blown! ğŸ¬'}, {'id': 4158, 'content': 'Grateful for the little things today ğŸŒ¸'}]}, 'match': 'no', 'confidence': 0.8, 'reasons': ['Strong conflict in current company (Microsoft/Shopee)', 'Strong conflict in job title/industry (Legal Professional/Manager)', 'No alignment in education details or skills'], 'score': 0.09999999999999999}, {'candidate': {'id': 823, 'display_name': 'Rahul Sharma', 'city': 'Singapore', 'country': 'Singapore', 'match_type': 'exact'}, 'profile': {'id': 823, 'display_name': 'Rahul Sharma', 'original_name': 'Rahul Sharma', 'city': 'Singapore', 'country': 'Singapore', 'hometown': 'London', 'bio': 'Wine Tasting â€¢ Golf â€¢ Documentaries | Based in Singapore', 'status': 'In a relationship', 'education': \"Master's Degree\", 'current_job': 'Analyst', 'current_company': 'UrbanFlow', 'interests': 'Wine Tasting, Golf, Documentaries, Language Learning', 'friend_count': 40, 'friends': [190, 6944, 3520, 1955, 7043, 2329, 3481, 8331, 1211, 5169, 7155, 4213, 9624, 6777, 3162, 6971, 5692, 3549, 3097, 869, 1082, 1142, 1327, 1394, 1655, 3033, 4239, 4352, 4703, 5130, 5465, 5727, 6411, 6492, 6687, 7253, 7716, 7818, 8257, 8724], 'posts': [{'id': 4462, 'content': 'Excited to start my new role as Analyst at UrbanFlow! ğŸ‰'}, {'id': 4463, 'content': 'Where should I travel next? Suggestions welcome! âœˆï¸'}, {'id': 4464, 'content': 'Mental health check: Taking time for self-care ğŸŒ¿'}, {'id': 4465, 'content': 'Finally getting back into Golf after ages!'}, {'id': 4466, 'content': 'Missing the food in Singapore already ğŸ˜‹'}, {'id': 4467, 'content': 'First project at UrbanFlow launched! Team effort all the way ğŸš€'}, {'id': 4468, 'content': 'Exploring hidden gems in Singapore. Local tips welcome! ğŸ‘‡'}]}, 'match': 'no', 'confidence': 0.9, 'reasons': ['Strong conflict in current company/role (Microsoft Senior Engineer vs UrbanFlow Analyst)', 'Strong conflict in industry (Legal Professional vs Analyst)', 'Strong conflict in skills (Compliance/Litigation vs no legal skills mentioned)', \"Education level conflict (PhD vs Master's Degree)\"], 'score': 0.075}, {'candidate': {'id': 909, 'display_name': 'Rahul Sharma', 'city': 'Manila', 'country': 'Philippines', 'match_type': 'exact'}, 'profile': {'id': 909, 'display_name': 'Rahul Sharma', 'original_name': 'Rahul Sharma', 'city': 'Manila', 'country': 'Philippines', 'hometown': 'Boston', 'bio': 'Finance | Passionate about Real Estate | Manila', 'status': 'In a relationship', 'education': \"Master's Degree\", 'current_job': 'Scientist', 'current_company': 'BCG', 'interests': 'Real Estate, Reading, Singing', 'friend_count': 41, 'friends': [333, 6049, 994, 8514, 3364, 5413, 7238, 5607, 138, 1098, 1838, 4430, 2286, 4691, 3381, 9174, 6267, 4030, 9087, 1402, 1421, 1533, 1660, 1804, 2055, 2499, 2606, 3634, 3771, 4138, 4551, 4986, 5747, 5819, 5857, 6444, 8052, 8115, 8572, 9155, 9425], 'posts': [{'id': 4932, 'content': \"Anyone else obsessed with Singing? Let's connect!\"}, {'id': 4933, 'content': 'Book recommendation: Just finished an amazing read! ğŸ“–'}, {'id': 4934, 'content': 'Grateful for the mentors who helped me grow in Philippines ğŸ™'}, {'id': 4935, 'content': 'Weekend getaway to Manila. Exactly what I needed! ğŸ—ºï¸'}, {'id': 4936, 'content': 'Exploring hidden gems in Manila. Local tips welcome! ğŸ‘‡'}, {'id': 4937, 'content': 'Morning walk with my dog in Manila ğŸ•'}, {'id': 4938, 'content': 'Finally getting back into Singing after ages!'}, {'id': 4939, 'content': 'Brunch goals at this Manila cafe â˜•âœ¨'}]}, 'match': 'no', 'confidence': 0.9, 'reasons': ['Major career field mismatch: resume is Legal Professional with strong legal skills, profile is Scientist at BCG with finance/real estate focus', 'Company conflict: resume shows Microsoft/StartupXYZ, profile shows BCG', \"Education conflict: resume has PhD in Legal Studies from Tsinghua, profile shows Master's Degree with unspecified field\"], 'score': 0.075}], 'best': {'candidate': {'id': 823, 'display_name': 'Rahul Sharma', 'city': 'Singapore', 'country': 'Singapore', 'match_type': 'exact'}, 'profile': {'id': 823, 'display_name': 'Rahul Sharma', 'original_name': 'Rahul Sharma', 'city': 'Singapore', 'country': 'Singapore', 'hometown': 'London', 'bio': 'Wine Tasting â€¢ Golf â€¢ Documentaries | Based in Singapore', 'status': 'In a relationship', 'education': \"Master's Degree\", 'current_job': 'Analyst', 'current_company': 'UrbanFlow', 'interests': 'Wine Tasting, Golf, Documentaries, Language Learning', 'friend_count': 40, 'friends': [190, 6944, 3520, 1955, 7043, 2329, 3481, 8331, 1211, 5169, 7155, 4213, 9624, 6777, 3162, 6971, 5692, 3549, 3097, 869, 1082, 1142, 1327, 1394, 1655, 3033, 4239, 4352, 4703, 5130, 5465, 5727, 6411, 6492, 6687, 7253, 7716, 7818, 8257, 8724], 'posts': [{'id': 4462, 'content': 'Excited to start my new role as Analyst at UrbanFlow! ğŸ‰'}, {'id': 4463, 'content': 'Where should I travel next? Suggestions welcome! âœˆï¸'}, {'id': 4464, 'content': 'Mental health check: Taking time for self-care ğŸŒ¿'}, {'id': 4465, 'content': 'Finally getting back into Golf after ages!'}, {'id': 4466, 'content': 'Missing the food in Singapore already ğŸ˜‹'}, {'id': 4467, 'content': 'First project at UrbanFlow launched! Team effort all the way ğŸš€'}, {'id': 4468, 'content': 'Exploring hidden gems in Singapore. Local tips welcome! ğŸ‘‡'}]}, 'match': 'no', 'confidence': 0.9, 'reasons': ['Strong conflict in current company/role (Microsoft Senior Engineer vs UrbanFlow Analyst)', 'Strong conflict in industry (Legal Professional vs Analyst)', 'Strong conflict in skills (Compliance/Litigation vs no legal skills mentioned)', \"Education level conflict (PhD vs Master's Degree)\"], 'score': 0.075}}}\n",
            "[Final] {'score': 0.2, 'verdict': 'no'}\n",
            "CV_4.pdf => 0.2\n",
            "\n",
            "==========================================================================================\n",
            "[DEBUG] CV_5.pdf\n",
            "[Extract] {'name': 'Rahul Sharma', 'title': 'Senior Engineer', 'locations': ['London', 'Hong Kong', 'Singapore'], 'companies': ['EY', 'StartupXYZ', 'DataForge'], 'schools': ['University of Tokyo']}\n",
            "[Select-LI] [{'id': 65, 'name': 'Rahul Sharma', 'location': 'Central, Hong Kong', 'match_type': 'exact'}, {'id': 95, 'name': 'Rahul Sharma', 'location': 'Kowloon, Hong Kong', 'match_type': 'exact'}, {'id': 564, 'name': 'Rahul Sharma', 'location': 'Central, Hong Kong', 'match_type': 'exact'}]\n",
            "[Select-FB] [{'id': 564, 'name': 'Rahul Sharma', 'location': 'Central, Hong Kong', 'match_type': 'exact'}, {'id': 7, 'name': 'Rahul Sharma', 'location': 'Sha Tin, Hong Kong', 'match_type': 'exact'}, {'id': 765, 'name': 'Rahul Sharma', 'location': 'Singapore, Singapore', 'match_type': 'exact'}]\n",
            "[Judge-LI] [{'match': 'no', 'confidence': 0.9, 'candidate': {'id': 65, 'name': 'Rahul Sharma', 'location': 'Central, Hong Kong', 'match_type': 'exact'}}, {'match': 'no', 'confidence': 0.2, 'candidate': {'id': 95, 'name': 'Rahul Sharma', 'location': 'Kowloon, Hong Kong', 'match_type': 'exact'}}, {'match': 'no', 'confidence': 0.9, 'candidate': {'id': 564, 'name': 'Rahul Sharma', 'location': 'Central, Hong Kong', 'match_type': 'exact'}}]\n",
            "[Judge-FB] [{'match': 'no', 'confidence': 0.2, 'candidate': {'id': 564, 'name': 'Rahul Sharma', 'location': 'Central, Hong Kong', 'match_type': 'exact'}}, {'match': 'no', 'confidence': 0.8, 'candidate': {'id': 7, 'name': 'Rahul Sharma', 'location': 'Sha Tin, Hong Kong', 'match_type': 'exact'}}, {'match': 'no', 'confidence': 0.2, 'candidate': {'id': 765, 'name': 'Rahul Sharma', 'location': 'Singapore, Singapore', 'match_type': 'exact'}}]\n",
            "[Aggregate] {'li': {'score': 0.075, 'verdict': 'no', 'matches': [{'candidate': {'id': 65, 'name': 'Rahul Sharma', 'headline': 'Software Professional', 'industry': 'Software', 'location': 'Central, Hong Kong', 'years_experience': 8, 'match_type': 'exact'}, 'profile': {'id': 65, 'name': 'Rahul Sharma', 'headline': 'Software Professional', 'city': 'Central', 'country': 'Hong Kong', 'industry': 'Software', 'status': 'open_to_work', 'years_experience': 8, 'summary': 'Citizen I decision walk next PM fact. Film popular her energy drive your. As difficult race poor ground charge administration.', 'skills': [{'name': 'Kubernetes', 'proficiency': 5}, {'name': 'Go', 'proficiency': 1}, {'name': 'Docker', 'proficiency': 3}], 'experience': [{'company': 'McKinsey', 'title': 'Manager', 'seniority': 'senior', 'start_year': 2021, 'end_year': 2027, 'is_current': False}, {'company': 'Gojek', 'title': 'Analyst', 'seniority': 'mid', 'start_year': 2009, 'end_year': None, 'is_current': False}], 'education': [{'school': 'HKUST', 'degree': 'PhD', 'field': 'Software', 'start_year': 2001, 'end_year': 2006}]}, 'match': 'no', 'confidence': 0.9, 'reasons': ['No overlap in companies, schools, or skills', 'Conflicting education details (University of Tokyo vs HKUST)', 'Conflicting experience timeline and roles'], 'score': 0.075}, {'candidate': {'id': 95, 'name': 'Rahul Sharma', 'headline': 'AI Professional', 'industry': 'AI', 'location': 'Kowloon, Hong Kong', 'years_experience': 16, 'match_type': 'exact'}, 'profile': {'id': 95, 'name': 'Rahul Sharma', 'headline': 'AI Professional', 'city': 'Kowloon', 'country': 'Hong Kong', 'industry': 'AI', 'status': 'student', 'years_experience': 16, 'summary': 'Prepare western rock structure. Into within free soon share. Loss between sea address store human. Control market political person crime force choose.', 'skills': [{'name': 'TensorFlow', 'proficiency': 3}, {'name': 'PyTorch', 'proficiency': 5}, {'name': 'NLP', 'proficiency': 1}, {'name': 'Python', 'proficiency': 2}, {'name': 'ML', 'proficiency': 4}], 'experience': [{'company': 'DataForge', 'title': 'Analyst', 'seniority': 'senior', 'start_year': 2017, 'end_year': None, 'is_current': False}, {'company': 'UrbanFlow', 'title': 'Scientist', 'seniority': 'mid', 'start_year': 2012, 'end_year': 2016, 'is_current': False}, {'company': 'EY', 'title': 'Engineer', 'seniority': 'mid', 'start_year': 2005, 'end_year': None, 'is_current': True}], 'education': [{'school': 'University of Tokyo', 'degree': 'MSc', 'field': 'AI', 'start_year': 2008, 'end_year': 2012}]}, 'match': 'no', 'confidence': 0.2, 'reasons': ['Major timeline conflicts in education and work experience', 'Conflicting seniority levels at overlapping companies', 'Degree level mismatch (PhD vs MSc)'], 'score': 0.25}, {'candidate': {'id': 564, 'name': 'Rahul Sharma', 'headline': 'Design Professional', 'industry': 'Design', 'location': 'Central, Hong Kong', 'years_experience': 9, 'match_type': 'exact'}, 'profile': {'id': 564, 'name': 'Rahul Sharma', 'headline': 'Design Professional', 'city': 'Central', 'country': 'Hong Kong', 'industry': 'Design', 'status': 'student', 'years_experience': 9, 'summary': 'By happen agent writer. Difficult brother majority capital own company these player. Maybe cut point phone present west. Church wife would small.', 'skills': [{'name': 'Prototyping', 'proficiency': 1}, {'name': 'Graphic Design', 'proficiency': 2}, {'name': 'UI/UX', 'proficiency': 4}], 'experience': [{'company': 'Alibaba', 'title': 'Manager', 'seniority': 'mid', 'start_year': 2011, 'end_year': 2015, 'is_current': True}], 'education': [{'school': 'Tsinghua University', 'degree': 'MBA', 'field': 'Design', 'start_year': 2004, 'end_year': 2009}]}, 'match': 'no', 'confidence': 0.9, 'reasons': ['Major conflict in industry/skills (AI/ML vs. Design/UI/UX)', 'No overlap in companies or schools', 'Conflicting experience timeline and seniority'], 'score': 0.075}], 'best': {'candidate': {'id': 65, 'name': 'Rahul Sharma', 'headline': 'Software Professional', 'industry': 'Software', 'location': 'Central, Hong Kong', 'years_experience': 8, 'match_type': 'exact'}, 'profile': {'id': 65, 'name': 'Rahul Sharma', 'headline': 'Software Professional', 'city': 'Central', 'country': 'Hong Kong', 'industry': 'Software', 'status': 'open_to_work', 'years_experience': 8, 'summary': 'Citizen I decision walk next PM fact. Film popular her energy drive your. As difficult race poor ground charge administration.', 'skills': [{'name': 'Kubernetes', 'proficiency': 5}, {'name': 'Go', 'proficiency': 1}, {'name': 'Docker', 'proficiency': 3}], 'experience': [{'company': 'McKinsey', 'title': 'Manager', 'seniority': 'senior', 'start_year': 2021, 'end_year': 2027, 'is_current': False}, {'company': 'Gojek', 'title': 'Analyst', 'seniority': 'mid', 'start_year': 2009, 'end_year': None, 'is_current': False}], 'education': [{'school': 'HKUST', 'degree': 'PhD', 'field': 'Software', 'start_year': 2001, 'end_year': 2006}]}, 'match': 'no', 'confidence': 0.9, 'reasons': ['No overlap in companies, schools, or skills', 'Conflicting education details (University of Tokyo vs HKUST)', 'Conflicting experience timeline and roles'], 'score': 0.075}}, 'fb': {'score': 0.09999999999999999, 'verdict': 'no', 'matches': [{'candidate': {'id': 564, 'display_name': 'Rahul Sharma', 'city': 'Central', 'country': 'Hong Kong', 'match_type': 'exact'}, 'profile': {'id': 564, 'display_name': 'Rahul Sharma', 'original_name': 'Rahul Sharma', 'city': 'Central', 'country': 'Hong Kong', 'hometown': 'Beijing', 'bio': 'By happen agent writer.  Difficult brother majority capital own company these player', 'status': 'Single', 'education': \"Master's Degree\", 'current_job': 'Manager', 'current_company': 'Alibaba', 'interests': 'Digital Art, Sketching, Networking', 'friend_count': 44, 'friends': [7168, 6021, 3471, 2962, 2453, 920, 7193, 4378, 5150, 9121, 1832, 8123, 2759, 5705, 9805, 6992, 8040, 9712, 1393, 5749, 9085, 1161, 1342, 1513, 2087, 3263, 3576, 3935, 3942, 4260, 4963, 5059, 5255, 5410, 5499, 6455, 6548, 6791, 7143, 7828, 7983, 8178, 8685, 9082], 'posts': [{'id': 3044, 'content': 'This Central restaurant is a hidden gem! ğŸ˜'}, {'id': 3045, 'content': 'Rest day = important day. Listen to your body! ğŸ’†'}, {'id': 3046, 'content': \"Proud to share: Our team hit this quarter's goals! ğŸ“ˆ\"}, {'id': 3047, 'content': 'Just another day in paradise ğŸŒ´'}, {'id': 3048, 'content': 'Throwback to my college days in Beijing. Time flies! ğŸ“¸'}]}, 'match': 'no', 'confidence': 0.2, 'reasons': ['Strong signal conflict: current company (EY vs Alibaba) and current title (Senior Engineer vs Manager) do not match.', \"Strong signal conflict: education level (PhD vs Master's Degree) does not match.\"], 'score': 0.25}, {'candidate': {'id': 7, 'display_name': 'Rahul Sharma', 'city': 'Sha Tin', 'country': 'Hong Kong', 'match_type': 'exact'}, 'profile': {'id': 7, 'display_name': 'Rahul Sharma', 'original_name': 'Rahul Sharma', 'city': 'Sha Tin', 'country': 'Hong Kong', 'hometown': 'Sha Tin', 'bio': 'Media message describe remember marriage.  Mission task could fact book player capital girl', 'status': 'In a relationship', 'education': \"Master's Degree\", 'current_job': 'Analyst', 'current_company': 'NextGen AI', 'interests': 'Writing, Public Policy, Rock Climbing, Surfing', 'friend_count': 51, 'friends': [5123, 1283, 7057, 5397, 7702, 6039, 3360, 8119, 3265, 4175, 7631, 726, 9693, 482, 2152, 8053, 7798, 6902, 6395, 34, 329, 645, 647, 699, 843, 1003, 1987, 2238, 2565, 3125, 3526, 3962, 4306, 4532, 5060, 5284, 5478, 5811, 6392, 6580, 6757, 7248, 7413, 7735, 7820, 7981, 8676, 8842, 9400, 9694, 9804], 'posts': [{'id': 33, 'content': 'Golden hour in Sha Tin hits different ğŸŒ…'}, {'id': 34, 'content': 'Completed my certification in Rock Climbing! Never stop learning ğŸ“š'}, {'id': 35, 'content': 'Living my best life in Sha Tin! ğŸŒŸ'}, {'id': 36, 'content': 'Grateful to be part of an amazing team at NextGen AI ğŸ’¼'}, {'id': 37, 'content': 'New year, new focus on Writing!'}, {'id': 38, 'content': 'Lazy Sunday vibes â˜ï¸'}]}, 'match': 'no', 'confidence': 0.8, 'reasons': ['Strong signal mismatch: current company (NextGen AI vs EY/DataForge)', 'Strong signal mismatch: current job title (Analyst vs Senior Engineer)', \"Strong signal mismatch: education level/degree (Master's vs PhD from University of Tokyo)\"], 'score': 0.09999999999999999}, {'candidate': {'id': 765, 'display_name': 'Rahul Sharma', 'city': 'Singapore', 'country': 'Singapore', 'match_type': 'exact'}, 'profile': {'id': 765, 'display_name': 'Rahul Sharma', 'original_name': 'Rahul Sharma', 'city': 'Singapore', 'country': 'Singapore', 'hometown': 'Singapore', 'bio': 'Inside still often other walk instead manage.  Management focus sort face degree most hold', 'status': 'In a civil union', 'education': \"Master's Degree\", 'current_job': 'Manager', 'current_company': 'Shopee', 'interests': 'Public Speaking, Networking, Photography', 'friend_count': 47, 'friends': [83, 162, 211, 283, 3715, 4875, 654, 9486, 7061, 5529, 6813, 4010, 3637, 8127, 3007, 8132, 8005, 8788, 7252, 2022, 486, 5094, 2278, 3950, 8050, 2930, 4601, 8828, 2427, 2897, 3084, 3457, 3972, 4020, 4791, 4792, 4929, 5058, 5221, 6352, 6658, 7063, 7155, 7226, 7548, 8726, 9089], 'posts': [{'id': 4151, 'content': 'Random acts of kindness make the world better â¤ï¸'}, {'id': 4152, 'content': \"What's everyone up to this weekend in Singapore?\"}, {'id': 4153, 'content': 'Throwback to my college days in Singapore. Time flies! ğŸ“¸'}, {'id': 4154, 'content': \"Travel goal for 2024: Finally visit Singapore! Who's been?\"}, {'id': 4155, 'content': 'Completed my certification in Photography! Never stop learning ğŸ“š'}, {'id': 4156, 'content': 'Grateful for friends who feel like family ğŸ™'}, {'id': 4157, 'content': 'Just finished binge-watching that new series. Mind blown! ğŸ¬'}, {'id': 4158, 'content': 'Grateful for the little things today ğŸŒ¸'}]}, 'match': 'no', 'confidence': 0.2, 'reasons': ['Strong conflict in current company (EY vs Shopee)', 'Strong conflict in current title (Senior Engineer vs Manager)', \"Strong conflict in highest education (PhD vs Master's)\"], 'score': 0.25}], 'best': {'candidate': {'id': 7, 'display_name': 'Rahul Sharma', 'city': 'Sha Tin', 'country': 'Hong Kong', 'match_type': 'exact'}, 'profile': {'id': 7, 'display_name': 'Rahul Sharma', 'original_name': 'Rahul Sharma', 'city': 'Sha Tin', 'country': 'Hong Kong', 'hometown': 'Sha Tin', 'bio': 'Media message describe remember marriage.  Mission task could fact book player capital girl', 'status': 'In a relationship', 'education': \"Master's Degree\", 'current_job': 'Analyst', 'current_company': 'NextGen AI', 'interests': 'Writing, Public Policy, Rock Climbing, Surfing', 'friend_count': 51, 'friends': [5123, 1283, 7057, 5397, 7702, 6039, 3360, 8119, 3265, 4175, 7631, 726, 9693, 482, 2152, 8053, 7798, 6902, 6395, 34, 329, 645, 647, 699, 843, 1003, 1987, 2238, 2565, 3125, 3526, 3962, 4306, 4532, 5060, 5284, 5478, 5811, 6392, 6580, 6757, 7248, 7413, 7735, 7820, 7981, 8676, 8842, 9400, 9694, 9804], 'posts': [{'id': 33, 'content': 'Golden hour in Sha Tin hits different ğŸŒ…'}, {'id': 34, 'content': 'Completed my certification in Rock Climbing! Never stop learning ğŸ“š'}, {'id': 35, 'content': 'Living my best life in Sha Tin! ğŸŒŸ'}, {'id': 36, 'content': 'Grateful to be part of an amazing team at NextGen AI ğŸ’¼'}, {'id': 37, 'content': 'New year, new focus on Writing!'}, {'id': 38, 'content': 'Lazy Sunday vibes â˜ï¸'}]}, 'match': 'no', 'confidence': 0.8, 'reasons': ['Strong signal mismatch: current company (NextGen AI vs EY/DataForge)', 'Strong signal mismatch: current job title (Analyst vs Senior Engineer)', \"Strong signal mismatch: education level/degree (Master's vs PhD from University of Tokyo)\"], 'score': 0.09999999999999999}}}\n",
            "[Final] {'score': 0.2, 'verdict': 'no'}\n",
            "CV_5.pdf => 0.2\n",
            "scores = [0.2, 0.2, 0.9850000000000001, 0.2, 0.2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation code\n",
        "\n",
        "In the test phase, you will be given 5 CV files with fixed names:\n",
        "\n",
        "    CV_1.pdf, CV_2.pdf, CV_3.pdf, CV_4.pdf, CV_5.pdf\n",
        "\n",
        "Your system must process these CVs and output a list of 5 scores,\n",
        "one score per CV, in the same order:\n",
        "\n",
        "    scores = [s1, s2, s3, s4, s5]\n",
        "\n",
        "Each score must be a float in the range [0, 1], representing the\n",
        "reliability or confidence that the CV is valid (or meets the task criteria).\n",
        "\n",
        "The ground-truth labels are binary:\n",
        "\n",
        "    groundtruth = [0 or 1, ..., 0 or 1]\n",
        "\n",
        "Each CV is evaluated independently using a threshold of 0.5:\n",
        "\n",
        "- If score > 0.5 and groundtruth == 1 â†’ Full credit\n",
        "- If score â‰¤ 0.5 and groundtruth == 0 â†’ Full credit\n",
        "- Otherwise â†’ No credit\n",
        "\n",
        "In other words, 0.5 is the decision threshold.\n",
        "\n",
        "- Each CV contributes equally.\n",
        "- Final score = (number of correct decisions) / 5\n"
      ],
      "metadata": {
        "id": "UqO99iOlq6mc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "#  Evaluation code\n",
        "# =====================================================\n",
        "\n",
        "def evaluate(scores, groundtruth, threshold=0.5):\n",
        "    \"\"\"\n",
        "    scores: list of floats in [0, 1], length = 5\n",
        "    groundtruth: list of ints (0 or 1), length = 5\n",
        "    \"\"\"\n",
        "    assert len(scores) == 5\n",
        "    assert len(groundtruth) == 5\n",
        "\n",
        "    correct = 0\n",
        "    decisions = []\n",
        "\n",
        "    for s, gt in zip(scores, groundtruth):\n",
        "        pred = 1 if s > threshold else 0\n",
        "        decisions.append(pred)\n",
        "        if pred == gt:\n",
        "            correct += 1\n",
        "\n",
        "    final_score = correct / len(scores)\n",
        "\n",
        "    return {\n",
        "        \"decisions\": decisions,\n",
        "        \"correct\": correct,\n",
        "        \"total\": len(scores),\n",
        "        \"final_score\": final_score\n",
        "    }\n"
      ],
      "metadata": {
        "id": "0TtL07airIqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scores = ... # Your code should generate this list [0.2, 0.3, 0.4, 0.5, 0.6]\n",
        "groundtruth = [1, 1, 1, 0, 0] # Do not modify\n",
        "\n",
        "result = evaluate(scores, groundtruth)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J14ltXjPtaMF",
        "outputId": "0f253737-9016-46ff-d018-b07154f240d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'decisions': [0, 0, 1, 0, 0], 'correct': 3, 'total': 5, 'final_score': 0.6}\n"
          ]
        }
      ]
    }
  ]
}